
__init__.py:
from .mermaid import MERMAID_DAG, show_mermaid_inline, show_mermaid_kroki
__all__ = ["MERMAID_DAG","show_mermaid_inline","show_mermaid_kroki"]



from typing import Dict, List, Optional
from collections import Counter

TYPE_CANON = {
    "journal-article": "journal article",
    "paper-conference": "conference paper",
    "proceedings-article": "conference paper",
    "book-chapter": "book chapter",
    "book": "book",
    "dataset": "dataset",
    "standard": "standard",
    "report": "technical report",
    "thesis": "thesis",
}

def reconcile_type(candidates: List[Dict[str, str]], llm_vote: Optional[str]) -> str:
    votes = []

    # LLM vote
    if llm_vote:
        votes.append(llm_vote.lower())

    # Online sources
    for c in candidates or []:
        source = c.get("source")
        if source == "crossref":
            t = c.get("cr_type", "")
            if t: votes.append(TYPE_CANON.get(t, t))
        elif source == "openalex":
            if c.get("oa_is_proceedings"): votes.append("conference paper")
        elif source == "semanticscholar":
            types = c.get("s2_types") or []
            if any("conference" in t for t in types): votes.append("conference paper")
            if any("journal" in t for t in types): votes.append("journal article")
            if any("book" in t for t in types): votes.append("book")
        elif source == "arxiv":
            votes.append("preprint")

    # Pick the majority vote
    if votes:
        return Counter(votes).most_common(1)[0][0]
    return "other"


scoring.py:
from typing import Any, Dict, List
from .utils import normalize_text, token_similarity, authors_to_list

def score_candidate(extracted: Dict[str, Any], cand: Dict[str, Any]) -> float:
    score = 0.0
    ex_doi = normalize_text(extracted.get("doi") or "").lower().replace("doi:","")
    ca_doi = normalize_text(cand.get("doi") or "").lower().replace("doi:","")
    if ex_doi and ca_doi and ex_doi == ca_doi: score += 1.0
    score += 0.6 * token_similarity(extracted.get("title") or "", cand.get("title") or "")
    ex_auth = [a.split()[-1].lower() for a in authors_to_list(extracted.get("authors")) if a.split()]
    ca_auth = [a.split()[-1].lower() for a in authors_to_list(cand.get("authors")) if a.split()]
    if ex_auth and ca_auth:
        inter = len(set(ex_auth) & set(ca_auth))
        score += 0.2 * (inter / max(1, len(set(ex_auth) | set(ca_auth))))
    ey = str(extracted.get("year") or "").strip()
    cy = str(cand.get("year") or "").strip()
    if ey and cy and ey == cy: score += 0.1
    src_weight = {"crossref": 0.12, "openalex": 0.08, "semanticscholar": 0.06, "pubmed": 0.05, "arxiv": 0.03}
    score += src_weight.get(cand.get("source",""), 0.0)
    return score

def is_trustworthy_match(ex, cand) -> bool:
    ex_doi = normalize_text(ex.get("doi")).lower().replace("doi:","")
    ca_doi = normalize_text(cand.get("doi")).lower().replace("doi:","")
    if ex_doi and ca_doi and ex_doi == ca_doi: return True
    t_sim = token_similarity(ex.get("title",""), cand.get("title",""))
    ex_last = {a.split()[-1].lower() for a in authors_to_list(ex.get("authors")) if a.split()}
    ca_last = {a.split()[-1].lower() for a in authors_to_list(cand.get("authors")) if a.split()}
    return (t_sim >= 0.8) and bool(ex_last & ca_last)


__init__.py:
from .utils import *
from .scoring import score_candidate, is_trustworthy_match
from .type_reconcile import reconcile_type
__all__ = ["score_candidate", "is_trustworthy_match", "reconcile_type"]


utils.py:
import re, json, hashlib
from typing import Any, Dict, List, Optional, Tuple
from datetime import datetime

DEFAULT_UA = "ieee-ref-agent/1.0 (mailto:you@example.com)"
SUFFIXES = {"jr", "jr.", "sr", "sr.", "ii", "iii", "iv", "v"}
MONTHS_NAME = {"1":"Jan","2":"Feb","3":"Mar","4":"Apr","5":"May","6":"Jun","7":"Jul","8":"Aug","9":"Sep","10":"Oct","11":"Nov","12":"Dec"}

try:
    from rapidfuzz import fuzz
    RF_AVAILABLE = True
except Exception:
    fuzz = None
    RF_AVAILABLE = False

_THIS_YEAR = datetime.utcnow().year

def safe_json_load(s: Any) -> Optional[Dict[str, Any]]:
    if s is None: return None
    if isinstance(s, dict): return s
    sx = s.decode("utf-8","ignore") if isinstance(s,(bytes,bytearray)) else str(s)
    sx = sx.strip()
    try:
        if sx.startswith("{"): return json.loads(sx)
    except Exception: ...
    i, n = 0, len(sx)
    while i < n and sx[i] != "{": i += 1
    if i >= n: return None
    stack=0; in_str=False; esc=False; start=None
    for j in range(i, n):
        ch = sx[j]
        if in_str:
            if esc: esc=False
            elif ch=="\\": esc=True
            elif ch=='"': in_str=False
        else:
            if ch=='"': in_str=True
            elif ch=="{":
                if stack==0: start=j
                stack+=1
            elif ch=="}":
                stack-=1
                if stack==0 and start is not None:
                    cand = sx[start:j+1]
                    try: return json.loads(cand)
                    except Exception: start=None
    return None

def normalize_text(x: Any) -> str:
    if x is None: return ""
    s = re.sub(r"\s+"," ", str(x).strip())
    return s

def norm_for_compare(x: Any) -> str:
    s = normalize_text(x).lower()
    s = re.sub(r"[^\w\s]"," ", s)
    s = re.sub(r"\s+"," ", s).strip()
    return s

def token_similarity(a: str, b: str) -> float:
    a = norm_for_compare(a); b = norm_for_compare(b)
    if not a or not b: return 0.0
    if RF_AVAILABLE and fuzz is not None: return fuzz.token_sort_ratio(a, b) / 100.0
    sa, sb = set(a.split()), set(b.split())
    inter = sa & sb
    union = sa | sb
    return len(inter) / max(1, len(union))

def authors_to_list(a: Any) -> List[str]:
    if not a: return []
    if isinstance(a, list): return [normalize_text(x) for x in a if normalize_text(x)]
    parts = re.split(r",\s*|\s+&\s+| and ", str(a))
    return [normalize_text(p) for p in parts if normalize_text(p)]

def _initials(given: str) -> List[str]:
    parts = re.split(r"\s+", given.strip()); out=[]
    for p in parts:
        if not p: continue
        hy = p.split("-")
        if len(hy)>1: out.append("-".join([h[0].upper()+"." for h in hy if h]))
        elif re.match(r"^[A-Za-z]\.$", p): out.append(p.upper())
        elif p.lower().rstrip(".") in SUFFIXES: out.append(p.capitalize().rstrip(".")+".")
        else: out.append(p[0].upper()+".")
    return out

def format_author_ieee(name: str) -> str:
    n = normalize_text(name)
    if not n: return ""
    if "," in n:
        last, given = [p.strip() for p in n.split(",", 1)]
    else:
        toks = n.split()
        if len(toks) == 1: return toks[0]
        last = toks[-1]; given=" ".join(toks[:-1])
    init = " ".join(_initials(given))
    last_tokens = last.split()
    if last_tokens and last_tokens[-1].lower().rstrip(".") in SUFFIXES:
        suf = last_tokens[-1].capitalize().rstrip(".")+"."
        last = " ".join(last_tokens[:-1])
        return f"{init} {last}, {suf}".strip(", ")
    return f"{init} {last}".strip()

def format_authors_ieee_list(auths: List[str]) -> str:
    items = [format_author_ieee(a) for a in auths if a]
    if not items: return ""
    if len(items) <= 6:
        return ", ".join(items[:-1]) + (", and " if len(items) > 1 else "") + items[-1] if len(items) > 1 else items[0]
    return ", ".join(items[:6]) + ", et al."

def heuristic_abbrev(fullname: str) -> str:
    return ""

def format_doi_link(doi: str) -> str:
    d = normalize_text(doi).lower().strip()
    for prefix in ["https://doi.org/", "http://doi.org/", "doi:"]:
        if d.startswith(prefix):
            d = d[len(prefix):].strip()
    d = d.replace("http://", "").replace("https://", "").replace("doi.org/", "").strip()
    return f"https://doi.org/{d}" if d else ""

def normalize_pages(p: str) -> Tuple[str, bool]:
    p = normalize_text(p).replace("—","-").replace("–","-")
    if not p: return "", False
    if ("-" not in p) and re.fullmatch(r"[A-Za-z]?\d+[A-Za-z]?", p):
        return p, True
    return p, False

def normalize_month_field(m: Any) -> str:
    s = normalize_text(m)
    if not s: return ""
    m_map = {"jan":"1","feb":"2","mar":"3","apr":"4","may":"5","jun":"6","jul":"7","aug":"8","sep":"9","sept":"9","oct":"10","nov":"11","dec":"12"}
    sl = s.strip(". ").lower()
    if sl in m_map: return m_map[sl]
    if re.fullmatch(r"0?[1-9]|1[0-2]", sl): return str(int(sl))
    return s

def fingerprint_state(ex: Dict[str, Any], best: Dict[str, Any], sugg: Dict[str, Any]) -> str:
    payload = json.dumps({"ex": ex, "best": best, "sugg": sugg}, sort_keys=True, ensure_ascii=False)
    return hashlib.sha256(payload.encode("utf-8","ignore")).hexdigest()

def safe_str(v: Any) -> str:
    try:
        if v is None: return ""
        return str(v).strip()
    except Exception:
        return ""

# ---- NEW: stronger year helpers ----
def is_plausible_year(y: Any) -> bool:
    try:
        yi = int(str(y).strip()[:4])
    except Exception:
        return False
    return 1800 <= yi <= (_THIS_YEAR + 1)

def coerce_year(y: Any) -> str:
    s = normalize_text(y)
    if not s: return ""
    m = re.search(r"\b(1[89]\d{2}|20\d{2})\b", s)
    if not m: return ""
    return m.group(1)


http.py:
import asyncio
from typing import Any, Dict, Optional
from cachetools import TTLCache
from ..tools.utils import DEFAULT_UA
try:
    import httpx
except Exception:
    httpx = None

class SourceClient:
    NAME: str = "base"
    def __init__(self, cfg, client=None, limiter=None, cache: Optional[TTLCache]=None):
        self.cfg = cfg
        self.client = client or (httpx.AsyncClient(timeout=self.cfg.timeout_s) if httpx is not None else None)
        self.limiter = limiter or asyncio.Semaphore(cfg.concurrency)
        self.cache = cache

    def _cache_get(self, key: str):
        if not self.cache: return None
        return self.cache.get((self.NAME, key))

    def _cache_set(self, key: str, val: Dict[str, Any]):
        if not self.cache: return
        self.cache[(self.NAME, key)] = val

    async def _get_json(self, url: str, params: Optional[Dict[str, Any]] = None, headers: Optional[Dict[str, str]] = None) -> Dict[str, Any]:
        if self.client is None:
            raise RuntimeError("HTTP client unavailable.")
        hdrs = {"User-Agent": DEFAULT_UA}
        if headers: hdrs.update(headers)
        attempt = 0
        while True:
            attempt += 1
            try:
                async with self.limiter:
                    r = await self.client.get(url, params=params, headers=hdrs)
                if r.status_code in (429, 500, 502, 503, 504) and attempt <= 4:
                    await asyncio.sleep(min(2**attempt, 8) + (0.1 * attempt))
                    continue
                r.raise_for_status()
                ct = r.headers.get("content-type","")
                if "json" in ct: return r.json()
                return {"_raw": r.text}
            except Exception:
                if attempt <= 2:
                    await asyncio.sleep(0.3 * attempt)
                    continue
                raise

    async def by_doi(self, doi: str): raise NotImplementedError
    async def by_title(self, title: str): raise NotImplementedError


pubmed.py:
from typing import Any, Dict, Optional
from ..http import SourceClient

class PubMedClient(SourceClient):
    NAME = "pubmed"
    ESEARCH = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi"
    ESUMMARY = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi"

    async def by_doi(self, doi: str) -> Optional[Dict[str, Any]]:
        return None

    async def by_title(self, title: str) -> Optional[Dict[str, Any]]:
        key = f"title:{title.lower()}"
        if (c := self._cache_get(key)): return c
        try:
            d = await self._get_json(self.ESEARCH, params={"db":"pubmed","term":title,"retmode":"json","retmax":"1","tool":"refassist","email":"you@example.com"})
            ids = d.get("esearchresult", {}).get("idlist", [])
            if not ids: return None
            pmid = ids[0]
            d2 = await self._get_json(self.ESUMMARY, params={"db":"pubmed","id":pmid,"retmode":"json","tool":"refassist","email":"you@example.com"})
            res = d2.get("result", {}).get(pmid)
            if res: self._cache_set(key, res)
            return res
        except Exception: return None


arxiv.py:
import re
from typing import Any, Dict, Optional
from ..http import SourceClient
from ..utils import normalize_text, DEFAULT_UA

class ArxivClient(SourceClient):
    NAME = "arxiv"; BASE_URL = "https://export.arXiv.org/api/query"

    async def by_doi(self, doi: str) -> Optional[Dict[str, Any]]:
        return None

    async def by_title(self, title: str) -> Optional[Dict[str, Any]]:
        try:
            if self.client is None: return None
            async with self.limiter:
                r = await self.client.get(self.BASE_URL, params={"search_query": f"ti:\"{title}\"", "start":0, "max_results":1}, headers={"Accept":"application/atom+xml","User-Agent":DEFAULT_UA})
                r.raise_for_status()
                xml = r.text
                tmatch = re.search(r"<title>(.*?)</title>", xml, flags=re.DOTALL)
                if not tmatch: return None
                title0 = normalize_text(re.sub(r"\s+", " ", tmatch.group(1)))
                auths = [normalize_text(a) for a in re.findall(r"<name>(.*?)</name>", xml)]
                ymatch = re.search(r"<published>(\d{4})-", xml)
                year0 = ymatch.group(1) if ymatch else ""
                return {"title": title0, "authors": auths, "journal_name":"arXiv", "year": year0, "doi":""}
        except Exception:
            return None

    async def by_id(self, arx: str) -> Optional[Dict[str, Any]]:
        try:
            if self.client is None: return None
            async with self.limiter:
                r = await self.client.get(self.BASE_URL, params={"id_list": arx}, headers={"Accept":"application/atom+xml","User-Agent":DEFAULT_UA})
                r.raise_for_status()
                xml = r.text
                tmatch = re.search(r"<title>(.*?)</title>", xml, flags=re.DOTALL)
                if not tmatch: return None
                title0 = normalize_text(re.sub(r"\s+", " ", tmatch.group(1)))
                auths = [normalize_text(a) for a in re.findall(r"<name>(.*?)</name>", xml)]
                ymatch = re.search(r"<published>(\d{4})-", xml)
                year0 = ymatch.group(1) if ymatch else ""
                return {"title": title0, "authors": auths, "journal_name":"arXiv", "year": year0, "doi":""}
        except Exception:
            return None


__init__.py:
from .crossref import CrossrefClient
from .openalex import OpenAlexClient
from .semanticscholar import SemanticScholarClient
from .pubmed import PubMedClient
from .arxiv import ArxivClient
__all__ = ["CrossrefClient","OpenAlexClient","SemanticScholarClient","PubMedClient","ArxivClient"]


openalex.py:
from typing import Any, Dict, List, Optional
from ..http import SourceClient
from ..utils import DEFAULT_UA

class OpenAlexClient(SourceClient):
    NAME = "openalex"; BASE_URL = "https://api.openalex.org/works"
    async def by_doi(self, doi: str) -> Optional[Dict[str, Any]]:
        key = f"doi:{doi.lower().strip()}"
        if (c := self._cache_get(key)): return c
        try:
            data = await self._get_json(self.BASE_URL, params={"filter": f"doi:{doi}"}, headers={"User-Agent": DEFAULT_UA})
            items = data.get("results", [])
            it = items[0] if items else None
            if it: self._cache_set(key, it)
            return it
        except Exception: return None

    async def by_title(self, title: str) -> Optional[List[Dict[str, Any]]]:
        try:
            data = await self._get_json(self.BASE_URL, params={"filter": f"title.search:{title}", "per-page":5}, headers={"User-Agent": DEFAULT_UA})
            return (data.get("results") or [])[:5]
        except Exception: return None


crossref.py:
from typing import Any, Dict, List, Optional
from ..http import SourceClient

class CrossrefClient(SourceClient):
    NAME = "crossref"; BASE_URL = "https://api.crossref.org/works"

    async def by_doi(self, doi: str) -> Optional[Dict[str, Any]]:
        key = f"doi:{doi.lower().strip()}"
        if (c := self._cache_get(key)): return c
        try:
            data = await self._get_json(f"{self.BASE_URL}/{doi}")
            msg = data.get("message")
            if msg: self._cache_set(key, msg)
            return msg
        except Exception: return None

    async def by_title(self, title: str) -> Optional[List[Dict[str, Any]]]:
        key = f"title:{title.lower()}"
        params = {
            "query.title": title,
            "rows": 5,
            "select": "title,author,container-title,short-container-title,issued,DOI,page,volume,issue,published-print,published-online,type"
        }
        try:
            data = await self._get_json(self.BASE_URL, params=params)
            items = data.get("message", {}).get("items", [])[:5]
            if items: self._cache_set(key, items[0])
            return items
        except Exception: return None


semanticscholar.py:
import os
from typing import Any, Dict, List, Optional
from ..http import SourceClient
from ..utils import DEFAULT_UA

class SemanticScholarClient(SourceClient):
    NAME = "semanticscholar"; BASE_URL = "https://api.semanticscholar.org/graph/v1/paper"
    S2_KEY = os.getenv("SEMANTIC_SCHOLAR_API_KEY")

    def _headers(self):
        h = {"User-Agent": DEFAULT_UA}
        if self.S2_KEY: h["x-api-key"] = self.S2_KEY
        return h

    async def by_doi(self, doi: str) -> Optional[Dict[str, Any]]:
        key = f"doi:{doi.lower().strip()}"
        if (c := self._cache_get(key)): return c
        try:
            data = await self._get_json(
                f"{self.BASE_URL}/DOI:{doi}",
                params={"fields":"title,venue,year,authors,externalIds,publicationVenue,publicationTypes"},
                headers=self._headers()
            )
            if data and not data.get("error"): self._cache_set(key, data)
            return data if data and not data.get("error") else None
        except Exception: return None

    async def by_title(self, title: str) -> Optional[List[Dict[str, Any]]]:
        try:
            data = await self._get_json(
                f"{self.BASE_URL}/search",
                params={"query": title, "limit":5, "fields":"title,venue,year,authors,externalIds,publicationVenue,publicationTypes"},
                headers=self._headers()
            )
            return (data.get("data") or [])[:5]
        except Exception: return None


format_reference.py:
from ..state import PipelineState
from ..tools.utils import (
  authors_to_list, format_authors_ieee_list,
  normalize_text, normalize_pages, normalize_month_field,
  MONTHS_NAME, format_doi_link
)

def format_reference(state: PipelineState) -> PipelineState:
    ex = state["extracted"]; rtype = (state["type"] or "other").lower()
    A = authors_to_list(ex.get("authors") or [])
    A_fmt = format_authors_ieee_list(A)
    title_raw = ex.get("title") or ""
    title = title_raw
    journal = ex.get("journal_abbrev") or ex.get("journal_name") or ""
    vol = normalize_text(ex.get("volume") or "")
    issue = normalize_text(ex.get("issue") or "")
    pages_raw = normalize_text(ex.get("pages") or "")
    pages_norm, is_eloc = normalize_pages(pages_raw)
    if "-" in pages_norm: pages_norm = pages_norm.replace("-", "–")
    year = normalize_text(ex.get("year") or "")
    month = normalize_month_field(ex.get("month") or "")
    month_disp = MONTHS_NAME.get(month, month) if month else ""
    doi_link = format_doi_link(ex.get("doi") or "")
    conf = normalize_text(ex.get("conference_name") or "")
    loc = normalize_text(ex.get("location") or "")
    pub = normalize_text(ex.get("publisher") or "")
    edition = normalize_text(ex.get("edition") or "")
    isbn = normalize_text(ex.get("isbn") or "")

    parts = []
    if A_fmt: parts.append(A_fmt)
    include_quoted_title = rtype not in ("book",)
    if include_quoted_title and title: parts.append(f"\"{title}\"")

    if rtype in ("journal article","journal"):
        if journal: parts.append(f"*{journal}*")
        if vol: parts.append(f"vol. {vol}")
        if issue: parts.append(f"no. {issue}")
        if pages_norm: parts.append(f"Art. no. {pages_norm}" if is_eloc else f"pp. {pages_norm}")
        date = " ".join([m for m in [month_disp, year] if m]).strip()
        if date: parts.append(date)
        if doi_link: parts.append(doi_link)

    elif rtype == "conference paper":
        venue = conf or journal or "Proceedings"
        if venue: parts.append(f"in *{venue}*")
        if loc: parts.append(loc)
        if pages_norm: parts.append(f"pp. {pages_norm}")
        date = " ".join([m for m in [month_disp, year] if m]).strip()
        if date: parts.append(date)
        if doi_link: parts.append(doi_link)

    elif rtype == "preprint":
        parts.append("preprint")
        if journal and "arxiv" in journal.lower(): parts.append(journal)
        date = " ".join([m for m in [month_disp, year] if m]).strip()
        if date: parts.append(date)
        if doi_link: parts.append(doi_link)

    elif rtype == "book":
        if title: parts.append(f"*{title}*")
        if edition: parts.append(f"{edition} ed.")
        imprint = f"{loc}: {pub}" if (loc and pub) else (loc or pub)
        if imprint: parts.append(imprint)
        if year: parts.append(year)
        if isbn: parts.append(f"ISBN: {isbn}")
        if doi_link: parts.append(doi_link)

    elif rtype in ("book chapter","chapter"):
        book_title = (ex.get("book_title") or conf or journal or "").strip()
        if book_title: parts.append(f"in *{book_title}*")
        if pages_norm: parts.append(f"pp. {pages_norm}")
        if pub: parts.append(pub)
        date = " ".join([m for m in [month_disp, year] if m]).strip()
        if date: parts.append(date)
        if doi_link: parts.append(doi_link)

    else:
        venue = journal or conf or pub
        if venue: parts.append(venue)
        date = " ".join([m for m in [month_disp, year] if m]).strip()
        if date: parts.append(date)
        if vol: parts.append(f"vol. {vol}")
        if issue: parts.append(f"no. {issue}")
        if pages_norm: parts.append(f"pp. {pages_norm}")
        if doi_link: parts.append(doi_link)

    state["formatted"] = (", ".join([p for p in parts if p]) + ".").replace(" ,", ",")
    return state


build_exports.py:
from ..state import PipelineState
from ..tools.utils import authors_to_list, safe_str, format_doi_link, normalize_month_field

def _to_csl_json(ex, rtype):
    typemap = {
        "journal article": "article-journal",
        "conference paper": "paper-conference",
        "book": "book",
        "book chapter": "chapter",
        "thesis": "thesis",
        "technical report": "report",
        "dataset": "dataset",
        "standard": "standard",
        "software": "software",
        "preprint": "article",
    }
    t = typemap.get(rtype, "article")

    authors = []
    for a in authors_to_list(ex.get("authors")):
        parts = a.split()
        family = parts[-1] if parts else a
        given = " ".join(parts[:-1]) if len(parts) > 1 else ""
        authors.append({"family": safe_str(family), "given": safe_str(given)})

    year_raw = ex.get("year")
    month_raw = normalize_month_field(ex.get("month") or "")
    issued = None
    try:
        y = int(year_raw) if safe_str(year_raw).isdigit() else None
        if y is not None:
            issued = {"date-parts": [[y, int(month_raw)]]} if (month_raw and month_raw.isdigit()) else {"date-parts": [[y]]}
    except Exception:
        issued = None

    doi_link = format_doi_link(ex.get("doi") or "")
    csl = {
        "type": t,
        "title": safe_str(ex.get("title")),
        "author": authors if authors else None,
        "container-title": safe_str(ex.get("journal_name") or ex.get("conference_name")),
        "container-title-short": safe_str(ex.get("journal_abbrev")) or None,
        "volume": safe_str(ex.get("volume")),
        "issue": safe_str(ex.get("issue")),
        "page": safe_str(ex.get("pages")),
        "DOI": safe_str(ex.get("doi")),
        "URL": doi_link or safe_str(ex.get("url")),
        "publisher": safe_str(ex.get("publisher")),
        "issued": issued,
    }
    return {k: v if v not in ("", None, []) else None for k, v in csl.items() if v not in ("", None, [])}

def _to_bibtex(ex, rtype):
    import re, hashlib
    def esc(s: str) -> str:
        return (s.replace("\\","\\textbackslash{}").replace("{","\\{").replace("}","\\}")
                  .replace("&","\\&").replace("%","\\%").replace("$","\\$")
                  .replace("#","\\#").replace("_","\\_"))

    authors_list = authors_to_list(ex.get("authors"))
    first_author_last = ""
    if authors_list:
        parts = authors_list[0].split()
        first_author_last = parts[-1] if parts else authors_list[0]

    year_str = safe_str(ex.get("year"))
    fa_key = re.sub(r"[^A-Za-z0-9]+", "", safe_str(first_author_last)) or "ref"
    yr_key = re.sub(r"[^0-9]+", "", year_str)
    if not yr_key:
        basis = safe_str(ex.get("doi")) or safe_str(ex.get("title"))
        h = hashlib.sha1(basis.encode("utf-8","ignore")).hexdigest()[:6] if basis else "000000"
        yr_key = h
    key = f"{fa_key}{yr_key}"

    entry_type = {
        "journal article": "article",
        "conference paper": "inproceedings",
        "book": "book",
        "book chapter": "incollection",
        "thesis": "phdthesis",
        "technical report": "techreport",
        "dataset": "misc",
        "standard": "misc",
        "software": "misc",
        "preprint": "misc",
    }.get(rtype, "misc")

    A = " and ".join(authors_list)
    title = safe_str(ex.get("title")); journal = safe_str(ex.get("journal_name"))
    conf = safe_str(ex.get("conference_name")); volume = safe_str(ex.get("volume"))
    number = safe_str(ex.get("issue")); pages = safe_str(ex.get("pages"))
    year = safe_str(ex.get("year")); doi = safe_str(ex.get("doi"))
    publisher = safe_str(ex.get("publisher")); isbn = safe_str(ex.get("isbn"))
    url_or_doi = format_doi_link(doi) if doi else safe_str(ex.get("url"))

    fields = []
    if entry_type == "article":
        fields += [("author", A), ("title", title), ("journal", journal),
                   ("volume", volume), ("number", number), ("pages", pages),
                   ("year", year)]
        if url_or_doi: fields.append(("url", url_or_doi))
        if doi and not url_or_doi: fields.append(("doi", doi))
    elif entry_type == "inproceedings":
        fields += [("author", A), ("title", title), ("booktitle", conf or journal),
                   ("pages", pages), ("year", year)]
        if url_or_doi: fields.append(("url", url_or_doi))
    elif entry_type == "book":
        fields += [("author", A), ("title", title), ("publisher", publisher),
                   ("year", year), ("isbn", isbn)]
        if url_or_doi: fields.append(("url", url_or_doi))
    elif entry_type == "incollection":
        fields += [("author", A), ("title", title), ("booktitle", conf or journal),
                   ("pages", pages), ("publisher", publisher), ("year", year)]
        if url_or_doi: fields.append(("url", url_or_doi))
    elif entry_type == "phdthesis":
        fields += [("author", A), ("title", title), ("school", publisher or conf or journal),
                   ("year", year)]
        if url_or_doi: fields.append(("url", url_or_doi))
    elif entry_type == "techreport":
        fields += [("author", A), ("title", title), ("institution", publisher or conf or journal),
                   ("year", year)]
        if url_or_doi: fields.append(("url", url_or_doi))
    else:
        fields += [("author", A), ("title", title), ("howpublished", conf or journal or publisher),
                   ("year", year)]
        if url_or_doi: fields.append(("url", url_or_doi))

    fields = [(k, esc(v)) for k, v in fields if v]
    body = ",\n  ".join([f"{k} = {{{v}}}" for k, v in fields])
    return f"@{entry_type}{{{key},\n  {body}\n}}"

def build_exports(state: PipelineState) -> PipelineState:
    ex = state["extracted"]; rtype = (state["type"] or "other").lower()
    state["csl_json"] = _to_csl_json(ex, rtype)
    state["bibtex"] = _to_bibtex(ex, rtype)
    return state


__init__.py:
from .init_runtime import init_runtime
from .detect_type import detect_type
from .parse_extract import parse_extract
from .multisource_lookup import multisource_lookup
from .select_best import select_best
from .verify_agents import verify_agents
from .apply_corrections import apply_corrections
from .llm_correct import llm_correct
from .enrich_from_best import enrich_from_best
from .format_reference import format_reference
from .build_exports import build_exports
from .build_report import build_report
from .cleanup import cleanup
from .routing import should_exit, route_after_verify
from .validate_reference import validate_input_reference
from .verify_journal_abbrev import verify_journal_abbrev
from .llm_format import llm_format  # NEW

__all__ = [
    "init_runtime","detect_type","parse_extract","multisource_lookup","select_best",
    "verify_agents","apply_corrections","llm_correct","enrich_from_best",
    "format_reference","build_exports","build_report","cleanup","should_exit","route_after_verify",
    "validate_input_reference","verify_journal_abbrev","llm_format",
]


detect_type.py:
import re
from ..state import PipelineState
from ..tools.type_reconcile import reconcile_type

async def detect_type(state: PipelineState) -> PipelineState:
    ref = state["reference"]
    llm = state["_llm"]

    # Ask LLM for type classification
    vote = await llm.json(
        "Classify this reference into one of: journal article, conference paper, book, book chapter, "
        "thesis, technical report, dataset, standard, software, other. "
        "Return JSON {\"type\": \"...\"}. Ref:\n" + ref
    )

    # Print LLM output for debugging
    print("=== LLM Type Vote ===")
    print(vote)
    print("=====================")

    # Save the LLM type vote in state
    state["_llm_type_vote"] = (vote or {}).get("type")

    # Use online candidates if available; otherwise empty list
    candidates = state.get("candidates", [])

    # Reconcile using only LLM + online sources
    state["type"] = reconcile_type(candidates=candidates, llm_vote=state["_llm_type_vote"])
    
    return state


verify_journal_abbrev.py:
import requests
from typing import Any, Dict
from ..state import PipelineState


def verify_journal_abbrev(state: PipelineState) -> PipelineState:
    """
    Verify journal abbreviation using NLM Catalog API.
    Updates state.extracted['verified_journal_abbrev'] and logs issues in state.corrections or state.verification_message.
    """
    journal = state.get("extracted", {}).get("journal_name", "")
    current_abbrev = state.get("extracted", {}).get("journal_abbrev", "")
    
    if not journal:
        state["verification_message"] = state.get("verification_message", "") + "No journal name provided for abbreviation verification. "
        state["corrections"] = state.get("corrections", []) + [("journal_abbrev", current_abbrev, "Missing journal name")]
        return state

    try:
        url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi"
        params = {
            "db": "nlmcatalog",
            "term": f"{journal}[Journal]",
            "retmode": "json",
            "retmax": 1
        }
        response = requests.get(url, params=params, timeout=5)
        response.raise_for_status()
        data = response.json()

        if data.get("esearchresult", {}).get("idlist"):
            nlm_id = data["esearchresult"]["idlist"][0]
            summary_url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi"
            summary_params = {
                "db": "nlmcatalog",
                "id": nlm_id,
                "retmode": "json"
            }
            summary_response = requests.get(summary_url, params=summary_params, timeout=5)
            summary_response.raise_for_status()
            summary_data = summary_response.json()

            journal_data = summary_data.get("result", {}).get(nlm_id, {})
            standard_abbrev = journal_data.get("isoabbreviation", "")
            
            if standard_abbrev:
                state["extracted"]["verified_journal_abbrev"] = standard_abbrev
                if current_abbrev and current_abbrev.lower() != standard_abbrev.lower():
                    state["corrections"] = state.get("corrections", []) + [
                        ("journal_abbrev", current_abbrev, standard_abbrev)
                    ]
                    state["verification_message"] = state.get("verification_message", "") + \
                        f"Journal abbreviation corrected: '{current_abbrev}' to '{standard_abbrev}'. "
            else:
                state["verification_message"] = state.get("verification_message", "") + \
                    f"No standard abbreviation found for journal: {journal}. "
                state["corrections"] = state.get("corrections", []) + [
                    ("journal_abbrev", current_abbrev, "Not found")
                ]
        else:
            state["verification_message"] = state.get("verification_message", "") + \
                f"Journal not found in NLM Catalog: {journal}. "
            state["corrections"] = state.get("corrections", []) + [
                ("journal_abbrev", current_abbrev, "Journal not found")
            ]
            
    except requests.RequestException as e:
        state["verification_message"] = state.get("verification_message", "") + \
            f"Failed to verify journal abbreviation: {str(e)}. "
        state["corrections"] = state.get("corrections", []) + [
            ("journal_abbrev", current_abbrev, f"Verification error: {str(e)}")
        ]
    
    return state

build_report.py:


import os
from docx import Document
from docx.shared import Pt
from ..state import PipelineState
from ..tools.utils import authors_to_list

TEMPLATE_PATH = os.path.join(os.getcwd(), "Template.docx")
EXPORTS_DIR = os.path.join(os.getcwd(), "exports")

def _format_corrections(changes, prov, audit):
    if not changes:
        return "No corrections were needed. 🎉"

    lines = []
    for f, old, new in changes:
        prov_source = audit.get(f) or prov.get(f) or "Unknown"
        if f == "authors":
            old_str = ", ".join(authors_to_list(old)) if old else "MISSING"
            new_str = ", ".join(authors_to_list(new)) if new else "MISSING"
            lines.append(f"- {f}: {old_str} → {new_str}  (source: {prov_source})")
        else:
            old_str = str(old) if old else "MISSING"
            new_str = str(new) if new else "MISSING"
            lines.append(f"- {f}: {old_str} → {new_str}  (source: {prov_source})")
    return "\n".join(lines)

def _format_provenance(best, ex, prov, audit):
    lines = []
    all_fields = [
        "title", "authors", "journal_name", "journal_abbrev", "conference_name",
        "volume", "issue", "pages", "year", "month", "doi",
        "publisher", "location", "edition", "isbn", "url"
    ]
    for f in all_fields:
        val = best.get(f) or ex.get(f)
        if not val:
            continue
        if f == "authors":
            val = ", ".join(authors_to_list(val))
        src = prov.get(f) or audit.get(f) or "Not available"
        lines.append(f"- {f}: {val}  (source: {src})")
    return "\n".join(lines)

def build_report(state: PipelineState) -> PipelineState:
    ex = state.get("extracted", {})
    best = state.get("best", {})
    prov = state.get("provenance", {}) or {}
    audit = state.get("audit", {}) or {}
    changes = state.get("corrections", [])
    ver = state.get("verification", {})
    matching_fields = set(state.get("matching_fields", []))
    formatted = state.get("formatted", "")
    fallback_used = not bool(formatted)
    failed = [k for k, v in ver.items() if not v]

    # Text chunks for placeholders
    overview = (
        f"- Type detected: {state.get('type','Unknown')}\n"
        f"- DOI: {best.get('doi') or 'Not available'}\n"
        f"- Primary source: {prov.get('doi') or prov.get('title') or 'Consensus'}"
    )

    verification = (
        f"Fields matched authoritative sources: {', '.join(sorted(matching_fields)) or 'None'}\n"
        f"Fields needing attention: {', '.join(sorted(failed)) or 'None'}"
    )

    corrections = _format_corrections(changes, prov, audit)
    provenance = _format_provenance(best, ex, prov, audit)

    formatting = (
        "LLM-based formatting applied successfully ✅" if formatted
        else "LLM formatting failed or skipped ❌\nFalling back to rule-based IEEE formatter ✅"
    )

    final_reference = formatted or state.get("ieee_formatted", "") or "Error: No formatted reference available."
    suggestions = (
        "- Verify fields needing attention manually." if failed else "- No manual action needed 🎉"
    )

    # ---------------------------------------------------------
    # 1. Update state["report"] for CLI output
    # ---------------------------------------------------------
    state["report"] = f"""
IEEE Reference Report

1. Overview
{overview}

2. Field Verification
{verification}

3. Corrections Applied
{corrections}

4. Provenance (Source per Field)
{provenance}

5. Formatting Strategy
{formatting}

6. Final Formatted Reference
{final_reference}

7. Suggested Actions
{suggestions}
"""

    # ---------------------------------------------------------
    # 2. Generate Word report using template.docx
    # ---------------------------------------------------------
    if not os.path.exists(EXPORTS_DIR):
        os.makedirs(EXPORTS_DIR)

    if not os.path.exists(TEMPLATE_PATH):
        # Fallback: generate basic docx if template missing
        doc = Document()
        doc.add_heading("IEEE Reference Report", level=1)
        doc.add_paragraph(state["report"])
        doc.save(os.path.join(EXPORTS_DIR, "report.docx"))
        state["report_path"] = os.path.join(EXPORTS_DIR, "report.docx")
        return state

    # Use the provided template.docx
    doc = Document(TEMPLATE_PATH)

    # Replace placeholders in all paragraphs
    placeholders = {
        "{OVERVIEW}": overview,
        "{VERIFICATION}": verification,
        "{CORRECTIONS}": corrections,
        "{PROVENANCE}": provenance,
        "{FORMATTING}": formatting,
        "{FINAL_REFERENCE}": final_reference,
        "{SUGGESTIONS}": suggestions,
    }

    for p in doc.paragraphs:
        for placeholder, value in placeholders.items():
            if placeholder in p.text:
                inline = p.runs
                for i in range(len(inline)):
                    if placeholder in inline[i].text:
                        inline[i].text = inline[i].text.replace(placeholder, value)

    # Save the customized report
    report_path = os.path.join(EXPORTS_DIR, "report.docx")
    doc.save(report_path)
    state["report_path"] = report_path

    return state


cleanup.py:
from ..state import PipelineState

async def cleanup(state: PipelineState) -> PipelineState:
    try:
        if state.get("_http") is not None:
            await state["_http"].aclose()
    except Exception:
        ...
    try:
        llm = state.get("_llm")
        if llm and llm.provider == "ollama" and getattr(llm, "_client", None) is not None:
            await llm._client.aclose()
    except Exception:
        ...
    return state


apply_corrections.py:
from typing import Any, Dict, List, Tuple
from ..state import PipelineState
from ..tools.utils import normalize_text, authors_to_list, normalize_month_field, fingerprint_state

_ALWAYS_REWRITE = {"title","authors","year","month","doi"}  # critical truth fields

def apply_corrections(state: PipelineState) -> PipelineState:
    ex = dict(state["extracted"])
    best = state.get("best", {}) or {}
    prov = state.get("provenance", {}) or {}
    suggestions = state.get("suggestions", {}) or {}
    matching_fields = set(state.get("matching_fields", []))
    changes: List[Tuple[str, Any, Any]] = []

    # store field -> source audit for the final report
    audit = dict(state.get("audit", {}))

    fields = [
        "title","authors","journal_name","journal_abbrev","volume","issue","pages",
        "doi","year","month","conference_name","publisher","location","edition","isbn","url"
    ]

    # Apply consensus-best (force for core truth fields)
    for k in fields:
        bv = best.get(k)
        if not bv: continue
        if (k in _ALWAYS_REWRITE) or (k not in matching_fields):
            if normalize_text(ex.get(k, "")) != normalize_text(bv):
                changes.append((k, ex.get(k), bv))
                ex[k] = bv
                # provenance for this correction
                if prov.get(k):
                    audit[k] = prov.get(k)

    # Suggestions on top
    for k, v in suggestions.items():
        if (k in _ALWAYS_REWRITE) or (k not in matching_fields):
            if normalize_text(ex.get(k, "")) != normalize_text(v):
                changes.append((k, ex.get(k), v))
                ex[k] = v
                # suggestions are from verify_agents / LLM; mark provenance if not already set
                audit.setdefault(k, "verify/llm")

    # Normalize
    if isinstance(ex.get("authors"), str):
        al = authors_to_list(ex["authors"])
        if al != ex["authors"]:
            changes.append(("authors_list", ex["authors"], al))
            ex["authors"] = al
            audit.setdefault("authors","normalize")

    if ex.get("month"):
        newm = normalize_month_field(ex["month"])
        if newm != ex["month"]:
            changes.append(("month_normalized", ex["month"], newm))
            ex["month"] = newm
            audit.setdefault("month","normalize")

    state["extracted"] = ex
    state["corrections"] = state.get("corrections", []) + changes
    state["attempts"] = state.get("attempts", 0) + 1
    state["_made_changes_last_cycle"] = bool(changes)
    state["audit"] = audit

    sugg = state.get("suggestions", {})
    best_now = state.get("best", {})
    new_fp = fingerprint_state(ex, best_now, sugg)
    hist = state.get("_fp_history", set())
    state["_loop_detected"] = new_fp in hist
    hist.add(new_fp)
    state["_fp_history"] = hist
    state["_fp"] = new_fp
    return state


enrich_from_best.py:
from ..state import PipelineState
from ..tools.utils import normalize_month_field

def enrich_from_best(state: PipelineState) -> PipelineState:
    ex = dict(state["extracted"]); be = state.get("best") or {}
    for k in ("journal_abbrev","journal_name","volume","issue","pages","year","month","doi","conference_name","publisher","location","edition","isbn","url","title","authors"):
        if not ex.get(k) and be.get(k):
            ex[k] = be.get(k)
    if ex.get("month"):
        ex["month"] = normalize_month_field(ex["month"])
    state["extracted"] = ex
    return state


init_runtime.py:
import asyncio
from cachetools import TTLCache
from ..config import PipelineConfig
from ..llms import LLMAdapter
from ..logging import logger
try:
    import httpx
except Exception:
    httpx=None

from ..state import PipelineState
from ..tools.sources import CrossrefClient, OpenAlexClient, SemanticScholarClient, PubMedClient, ArxivClient

async def init_runtime(state: PipelineState) -> PipelineState:
    cfg = state.get("_cfg") or PipelineConfig()
    llm = LLMAdapter(cfg)
    http = httpx.AsyncClient(timeout=httpx.Timeout(connect=cfg.timeout_s, read=cfg.timeout_s, write=cfg.timeout_s, pool=cfg.timeout_s)) if httpx is not None else None
    cache = TTLCache(maxsize=1000, ttl=cfg.cache_ttl_s)
    limiter = asyncio.Semaphore(cfg.concurrency)
    sources = [
        CrossrefClient(cfg, client=http, limiter=limiter, cache=cache),
        OpenAlexClient(cfg, client=http, limiter=limiter, cache=cache),
        SemanticScholarClient(cfg, client=http, limiter=limiter, cache=cache),
        PubMedClient(cfg, client=http, limiter=limiter, cache=cache),
        ArxivClient(cfg, client=http, limiter=limiter, cache=cache),
    ]
    state.update({
        "_cfg": cfg,
        "_llm": llm,
        "_http": http,
        "_cache": cache,
        "_limiter": limiter,
        "_sources": sources,
        "hops": state.get("hops", 0),
        "attempts": state.get("attempts", 0),
        "_ver_score": state.get("_ver_score", -1),
        "_stagnation": state.get("_stagnation", 0),
        "_fp": state.get("_fp", ""),
        "_fp_history": state.get("_fp_history", set()),
        "_loop_detected": False,
        "_made_changes_last_cycle": False,
        # NEW KEYS for reference verification
        "_skip_pipeline": False,
        "verification_message": "",
    })
    return state



multisource_lookup.py:
from typing import Any, Dict, List, Tuple
from ..state import PipelineState
from ..tools.utils import normalize_text
from ..tools.sources.arxiv import ArxivClient
import asyncio
import re

def _normalize_candidate(source: str, rec: Dict[str, Any]) -> Dict[str, Any]:
    from ..tools.utils import normalize_text
    out: Dict[str, Any] = {"source": source, "raw": rec}
    if source == "crossref":
        out["title"] = normalize_text((rec.get("title") or [""])[0]) if rec.get("title") else ""
        out["authors"] = [
            normalize_text(f"{a.get('given','')} {a.get('family','')}".strip())
            for a in rec.get("author", [])] if rec.get("author") else []
        out["journal_name"] = normalize_text((rec.get("container-title") or [""])[0]) if rec.get("container-title") else ""
        out["journal_abbrev"] = normalize_text((rec.get("short-container-title") or [""])[0]) if rec.get("short-container-title") else ""
        out["volume"] = normalize_text(rec.get("volume") or "")
        out["issue"] = normalize_text(rec.get("issue") or "")
        out["pages"] = normalize_text(rec.get("page") or "")
        out["doi"] = normalize_text(rec.get("DOI") or "")
        out["cr_type"] = normalize_text(rec.get("type") or "")
        y, m = "", ""
        for src in ("issued", "published-print", "published-online"):
            dp = (rec.get(src) or {}).get("date-parts")
            if dp:
                y = str(dp[0][0])
                if len(dp[0]) > 1:
                    m = str(dp[0][1])
                break
        out["year"], out["month"] = y, m
    elif source == "openalex":
        out["title"] = normalize_text(rec.get("display_name") or rec.get("title") or "")
        out["authors"] = [
            normalize_text(a.get("author", {}).get("display_name") or "")
            for a in rec.get("authorships", [])
        ] if rec.get("authorships") else []
        hv = rec.get("host_venue", {}) if isinstance(rec.get("host_venue"), dict) else {}
        out["journal_name"] = normalize_text(hv.get("display_name") or "")
        out["journal_abbrev"] = normalize_text(hv.get("abbrev") or "")
        out["doi"] = normalize_text(rec.get("doi") or "")
        out["volume"] = normalize_text(rec.get("biblio", {}).get("volume") or "")
        out["issue"] = normalize_text(rec.get("biblio", {}).get("issue") or "")
        fp = rec.get("biblio", {}).get("first_page") or ""
        lp = rec.get("biblio", {}).get("last_page") or ""
        out["pages"] = f"{fp}-{lp}" if fp and lp else normalize_text(fp or "")
        out["year"] = str(rec.get("publication_year") or (rec.get("from_publication_date") or "")[:4] or "")
        out["month"] = ""
        out["oa_is_proceedings"] = "proceedings" in (hv.get("display_name") or "").lower()
    elif source == "semanticscholar":
        out["title"] = normalize_text(rec.get("title") or "")
        out["authors"] = [normalize_text(a.get("name") or "") for a in rec.get("authors", [])] if rec.get("authors") else []
        out["journal_name"] = normalize_text(rec.get("venue") or (rec.get("publicationVenue") or {}).get("name") or "")
        out["journal_abbrev"] = ""
        eid = rec.get("externalIds") or {}
        out["doi"] = normalize_text(eid.get("DOI") or rec.get("doi") or "")
        out["year"] = normalize_text(rec.get("year") or "")
        out["month"] = ""
        out["s2_types"] = [normalize_text(t) for t in (rec.get("publicationTypes") or [])]
    elif source == "pubmed":
        out["title"] = normalize_text(rec.get("title") or rec.get("sorttitle") or "")
        out["authors"] = [normalize_text(a.get("name")) for a in rec.get("authors", []) if a.get("name")] if rec.get("authors") else []
        out["journal_name"] = normalize_text((rec.get("fulljournalname") or rec.get("source") or ""))
        out["journal_abbrev"] = normalize_text(rec.get("source") or "")
        out["doi"] = normalize_text((rec.get("elocationid") or "").replace("doi:", "").strip())
        out["volume"] = normalize_text(rec.get("volume") or "")
        out["issue"] = normalize_text(rec.get("issue") or "")
        out["pages"] = normalize_text(rec.get("pages") or "")
        out["year"] = normalize_text((rec.get("pubdate") or "").split(" ")[0])
        out["month"] = ""
    elif source == "arxiv":
        out["title"] = normalize_text(rec.get("title") or "")
        out["authors"] = [normalize_text(a) for a in rec.get("authors", [])]
        out["journal_name"] = "arXiv"
        out["journal_abbrev"] = "arXiv"
        out["doi"] = normalize_text(rec.get("doi") or "")
        out["year"] = normalize_text(rec.get("year") or "")
        out["month"] = ""
        out["volume"] = ""
        out["issue"] = ""
        out["pages"] = ""
    else:
        out.update({k: "" for k in ("title", "authors", "journal_name", "journal_abbrev", "doi", "volume", "issue", "pages", "year", "month")})
    return out

def _title_variants(title: str) -> List[str]:
    t = normalize_text(title)
    if not t:
        return []
    out = [t]
    # remove subtitle after colon/dash to improve recall
    m = re.split(r"\s*[:\-–—]\s*", t, maxsplit=1)
    if m and len(m[0]) >= 6:
        out.append(m[0])
    # Shorten very long titles
    if len(t) > 180:
        out.append(t[:180])
    # dedupe while keeping order
    seen = set()
    uniq = []
    for v in out:
        if v not in seen:
            seen.add(v)
            uniq.append(v)
    return uniq

async def multisource_lookup(state: PipelineState) -> PipelineState:
    ex, sources = state["extracted"], state["_sources"]
    doi = normalize_text(ex.get("doi") or "").lower().replace("doi:", "")
    title = normalize_text(ex.get("title") or "")
    arxiv_id = normalize_text(ex.get("arxiv_id") or "")

    tasks = []
    for s in sources:
        if arxiv_id and isinstance(s, ArxivClient):
            tasks.append(s.by_id(arxiv_id))
        if doi:
            tasks.append(s.by_doi(doi))
        if title:
            for tv in _title_variants(title):
                tasks.append(s.by_title(tv))

    results = await asyncio.gather(*tasks, return_exceptions=True)
    out_norm: List[Dict[str, Any]] = []
    idx = 0
    for s in sources:
        if arxiv_id and isinstance(s, ArxivClient):
            rec = results[idx]; idx += 1
            if rec:
                out_norm.append(_normalize_candidate(s.NAME, rec))
        if doi:
            rec = results[idx]; idx += 1
            if isinstance(rec, list):
                for r in rec:
                    out_norm.append(_normalize_candidate(s.NAME, r))
            elif isinstance(rec, dict) and rec:
                out_norm.append(_normalize_candidate(s.NAME, rec))
        if title:
            for _tv in _title_variants(title):
                rec = results[idx]; idx += 1
                if isinstance(rec, list):
                    for r in rec:
                        out_norm.append(_normalize_candidate(s.NAME, r))
                elif isinstance(rec, dict) and rec:
                    out_norm.append(_normalize_candidate(s.NAME, rec))

    dedup = {}
    for c in out_norm:
        key = (c["source"], (c.get("doi") or "").lower() or c.get("title") or "")
        dedup[key] = c
    state["candidates"] = list(dedup.values())
    return state


verify_agents.py:
from concurrent.futures import ThreadPoolExecutor, as_completed
from ..config import PipelineConfig
from ..state import PipelineState
from ..tools.utils import (
    heuristic_abbrev, token_similarity, authors_to_list, normalize_text, normalize_month_field, fingerprint_state
)

def normalize_author_name(author: str) -> str:
    """Normalize author name for comparison."""
    parts = author.strip().split()
    if not parts:
        return ""
    if parts[-1].lower() in ['al.', 'et', 'et.']:
        return ""
    initials = [p for p in parts[:-1] if p[0].isalpha() and (len(p) == 1 or p.endswith('.'))]
    surname = parts[-1] if parts[-1][0].isalpha() else ""
    return " ".join(initials + [surname]).lower().strip()

def _prefer_abbrev(be_ab: str, fallback: str) -> str:
    if be_ab: return be_ab
    return fallback

def agent_journal(extracted, best):
    ex_j = normalize_text(extracted.get("journal_name", ""))
    ex_ab = normalize_text(extracted.get("journal_abbrev", ""))
    be_j = normalize_text(best.get("journal_name", ""))
    be_ab = normalize_text(best.get("journal_abbrev", ""))
    sim_full = token_similarity(ex_j, be_j) if ex_j and be_j else 0.0
    sim_ab = token_similarity(ex_ab, be_ab) if ex_ab and be_ab else 0.0
    ok = (sim_full >= 0.8) or (sim_ab >= 0.8) or (bool(ex_j) and not be_j)
    corr = {}
    if be_j and be_j != ex_j: corr["journal_name"] = be_j
    if (be_ab and be_ab != ex_ab) or (not ex_ab and (be_ab or be_j)):
        chosen = _prefer_abbrev(be_ab, heuristic_abbrev(be_j or ex_j))
        corr["journal_abbrev"] = chosen
    return {"ok": ok, "correction": corr or None}

def agent_authors(extracted, best):
    ex = authors_to_list(extracted.get("authors", []))
    be = authors_to_list(best.get("authors", []))
    if not be:
        return {"ok": bool(ex), "correction": None}

    def norm_list(L):
        return [normalize_author_name(a) for a in L if normalize_author_name(a)]

    exn, ben = norm_list(ex), norm_list(be)
    if not exn or not ben:
        return {"ok": False, "correction": {"authors": be} if be else None}

    # exact list equality after normalization (ordered)
    if exn == ben:
        return {"ok": True, "correction": None}

    # allow minor order differences: if sets equal and length equal, still suggest canonical be
    if len(exn) == len(ben) and set(exn) == set(ben):
        return {"ok": True, "correction": {"authors": be}}

    return {"ok": False, "correction": {"authors": be}}

def agent_title(extracted, best):
    ex_t = normalize_text(extracted.get("title", ""))
    be_t = normalize_text(best.get("title", ""))
    if be_t:
        sim = token_similarity(ex_t, be_t)
        if sim >= 0.82:
            return {"ok": True}
        return {"ok": False, "correction": {"title": be_t}}
    return {"ok": bool(ex_t)}

def agent_year_month(extracted, best):
    ex_y = str(extracted.get("year", ""))
    ex_m = normalize_month_field(extracted.get("month", ""))
    be_y = str(best.get("year", ""))
    be_m = normalize_month_field(best.get("month", ""))
    ok = True
    corr = {}
    if be_y and be_y != ex_y: corr["year"] = be_y; ok = False
    if be_m and be_m != ex_m: corr["month"] = be_m; ok = False
    return {"ok": ok, "correction": corr or None}

def agent_vipd(extracted, best):
    ex_v, ex_i, ex_p, ex_d = [normalize_text(extracted.get(k, "")) for k in ("volume", "issue", "pages", "doi")]
    be_v, be_i, be_p, be_d = [normalize_text(best.get(k, "")) for k in ("volume", "issue", "pages", "doi")]
    ok = True
    corr = {}
    if be_v and be_v != ex_v: corr["volume"] = be_v; ok = False
    if be_i and be_i != ex_i: corr["issue"] = be_i; ok = False
    if be_p and be_p != ex_p: corr["pages"] = be_p; ok = False
    if be_d and be_d.lower().replace("doi:", "") != ex_d.lower().replace("doi:", ""):
        corr["doi"] = be_d; ok = False
    return {"ok": ok, "correction": corr or None}

def agent_presence(extracted, best):
    return {"ok": bool(extracted.get("title")) and bool(extracted.get("authors"))}

def verify_agents(state: PipelineState) -> PipelineState:
    ex = state["extracted"]
    be = state.get("best", {})
    matching_fields = state.get("matching_fields", [])
    agents = [agent_journal, agent_authors, agent_title, agent_year_month, agent_vipd, agent_presence]
    results = {}

    with ThreadPoolExecutor(max_workers=state["_cfg"].agent_threads) as pool:
        fut_map = {pool.submit(a, ex, be): a.__name__ for a in agents}
        for fut in as_completed(fut_map):
            name = fut_map[fut]
            try:
                results[name] = fut.result()
            except Exception:
                results[name] = {"ok": False}

    suggestions = {}
    for name, out in results.items():
        if out.get("correction"):
            for k, v in out["correction"].items():
                if k == "authors" or k not in matching_fields:
                    suggestions[k] = v

    vipd_ok = results.get("agent_vipd", {}).get("ok", False)
    ym_ok = results.get("agent_year_month", {}).get("ok", False)

    verification = {
        "title": results.get("agent_title", {}).get("ok", False) or "title" in matching_fields,
        "authors": results.get("agent_authors", {}).get("ok", False),
        "journal_name": results.get("agent_journal", {}).get("ok", False) or "journal_name" in matching_fields,
        "journal_abbrev": results.get("agent_journal", {}).get("ok", False) or "journal_abbrev" in matching_fields,
        "year": ym_ok or "year" in matching_fields,
        "month": ym_ok or "month" in matching_fields,
        "volume": vipd_ok or "volume" in matching_fields,
        "issue": vipd_ok or "issue" in matching_fields,
        "pages": vipd_ok or "pages" in matching_fields,
        "doi": vipd_ok or "doi" in matching_fields,
        "presence": results.get("agent_presence", {}).get("ok", False),
    }

    ver_score = sum(1 for v in verification.values() if v)
    last_score = state.get("_ver_score", -1)
    stagnation = state.get("_stagnation", 0)
    stagnation = 0 if ver_score > last_score else (stagnation + 1)

    state["_ver_score"] = ver_score
    state["_stagnation"] = stagnation
    state["verification"] = verification
    state["suggestions"] = suggestions
    state["hops"] = state.get("hops", 0) + 1

    fp = fingerprint_state(ex, be, suggestions)
    hist = state.get("_fp_history", set())
    state["_loop_detected"] = fp in hist
    hist.add(fp)
    state["_fp_history"] = hist
    state["_fp"] = fp
    return state


llm_format.py:
import re
from ..state import PipelineState
from ..tools.utils import normalize_text

IEEE_HINT = (
    "You are a precise IEEE reference formatter. "
    "Format a single reference in IEEE style using ONLY the provided fields. "
    "Do NOT invent or modify facts. If a field is missing, omit it. "
    "Output must be a single formatted reference line (no JSON, no commentary). "
    "Use italics with *asterisks* around container titles if present. "
    "Follow IEEE patterns for each type:\n"
    "- journal article: Authors, \"Title,\" *Journal*, vol. X, no. Y, pp. A–B or Art. no. N, Mon YYYY, https://doi.org/DOI.\n"
    "- conference paper: Authors, \"Title,\" in *Conference Name*, Location, pp. A–B, Mon YYYY, https://doi.org/DOI.\n"
    "- book: Authors, *Title*, Edition ed., Location: Publisher, YYYY, ISBN if provided, DOI/URL if provided.\n"
    "- book chapter: Authors, \"Title,\" in *Book Title*, pp. A–B, Publisher, Mon YYYY, DOI/URL.\n"
    "- preprint: Authors, \"Title,\" preprint (arXiv if indicated), Mon YYYY, DOI/URL.\n"
    "Ensure authors are in IEEE initials style if already provided that way; otherwise use as given. "
    "Never change the year, DOI, title, or authors — use them exactly as provided."
)

def _is_reasonable(ref: str) -> bool:
    if not ref or len(ref) < 20:
        return False
    # must contain at least a title quote or an italic block for containers, or a DOI/http
    if ("\"" in ref) or ("*") in ref or ("doi.org/" in ref) or ("http" in ref):
        return True
    return False

def _safe_line(s: str) -> str:
    s = s.strip()
    # collapse whitespace
    s = re.sub(r"\s+", " ", s)
    # ensure trailing period
    if s and not s.endswith("."):
        s += "."
    return s

async def llm_format(state: PipelineState) -> PipelineState:
    llm = state.get("_llm")
    ex = state.get("extracted", {}) or {}
    rtype = normalize_text(state.get("type") or "other")

    if not llm:
        return state

    # Build a locked, authoritative view for the LLM to format from.
    # We DO NOT let the LLM change these values — it only formats.
    payload_lines = [f"type: {rtype}"]
    for k in (
        "title","authors","journal_name","journal_abbrev","conference_name","volume","issue",
        "pages","year","month","doi","publisher","location","edition","isbn","url"
    ):
        v = ex.get(k)
        if v is None or v == "":
            continue
        if isinstance(v, list):
            payload_lines.append(f"{k}: {', '.join([str(x) for x in v])}")
        else:
            payload_lines.append(f"{k}: {v}")

    user_payload = "\n".join(payload_lines)

    prompt = (
        f"{IEEE_HINT}\n\n"
        f"Fields to use (authoritative; do not change values):\n{user_payload}\n\n"
        "Return exactly one IEEE-formatted reference line, nothing else."
    )

    out_text = (await llm.text(prompt)).strip() if hasattr(llm, "text") else ""
    if _is_reasonable(out_text):
        state["formatted"] = _safe_line(out_text)
    # If the LLM output is not reasonable, leave 'formatted' unset to trigger fallback.
    return state


select_best.py:
from collections import Counter, defaultdict
from typing import Dict, List, Tuple, Optional
from ..state import PipelineState
from ..tools.scoring import score_candidate, is_trustworthy_match
from ..tools.utils import normalize_text, token_similarity, authors_to_list, is_plausible_year, coerce_year

def _norm_author(author: str) -> str:
    parts = author.strip().split()
    if not parts: return ""
    if parts[-1].lower() in {"al.", "et", "et."}: return ""
    initials = [p[0].upper()+"." for p in parts[:-1] if p and p[0].isalpha()]
    surname = parts[-1] if parts[-1] and parts[-1][0].isalpha() else ""
    return (" ".join(initials + [surname])).strip().lower()

def _title_sim(a: str, b: str) -> float:
    return token_similarity(normalize_text(a), normalize_text(b))

def _cluster_by_title(cands: List[Dict]) -> List[List[Dict]]:
    clusters: List[List[Dict]] = []
    THRESH = 0.82
    for c in cands:
        placed = False
        for cl in clusters:
            if _title_sim(c.get("title",""), cl[0].get("title","")) >= THRESH:
                cl.append(c); placed=True; break
        if not placed:
            clusters.append([c])
    return clusters

def _w(src: str) -> float:
    return {"crossref":1.0,"openalex":0.8,"semanticscholar":0.6,"pubmed":0.55,"arxiv":0.4}.get((src or "").lower(), 0.2)

def _vote_field(cl: List[Dict], key: str) -> Tuple[str, float, Optional[str]]:
    bucket: Dict[str, float] = defaultdict(float)
    source_for: Dict[str, str] = {}
    for c in cl:
        v = normalize_text(c.get(key, ""))
        if not v: continue
        w = _w(c.get("source"))
        bucket[v] += w
        # keep first strongest source label for audit
        if v not in source_for or w > _w(source_for.get(v,"")):
            source_for[v] = c.get("source")
    if not bucket: return "", 0.0, None
    best_val, best_w = max(bucket.items(), key=lambda kv: kv[1])
    return best_val, best_w, source_for.get(best_val)

def _vote_authors(cl: List[Dict]) -> Tuple[List[str], float, Optional[str]]:
    bucket: Dict[Tuple[str,...], float] = defaultdict(float)
    raw_map: Dict[Tuple[str,...], List[str]] = {}
    src_map: Dict[Tuple[str,...], str] = {}
    for c in cl:
        raw = authors_to_list(c.get("authors", []))
        norm = tuple(a for a in [_norm_author(a) for a in raw] if a)
        if not norm: continue
        w = _w(c.get("source"))
        bucket[norm] += w
        if norm not in raw_map or len(raw_map[norm]) < len(raw):
            raw_map[norm] = raw
            src_map[norm] = c.get("source")
    if not bucket: return [], 0.0, None
    norm_best, w = max(bucket.items(), key=lambda kv: kv[1])
    return raw_map.get(norm_best, list(norm_best)), w, src_map.get(norm_best)

def _has_any_doi_agreement(cluster: List[Dict]) -> str:
    dois = [normalize_text(c.get("doi","")).lower().replace("doi:","") for c in cluster if c.get("doi")]
    dois = [d for d in dois if d]
    if not dois: return ""
    c = Counter(dois)
    doi, cnt = c.most_common(1)[0]
    if cnt >= 2 or any((ci.get("source") in {"crossref","openalex"} and normalize_text(ci.get("doi")).lower().replace("doi:","")==doi) for ci in cluster):
        return doi
    return ""

def _best_year(cl: List[Dict]) -> Tuple[str, str]:
    """
    Choose year with strong tie-break:
    1) Crossref year if plausible (from any of issued/published-* we normalized into 'year')
    2) OpenAlex
    3) SemanticScholar
    4) PubMed
    Otherwise modal plausible year.
    Returns (year, provenance_source)
    """
    by_src: Dict[str, List[str]] = defaultdict(list)
    for c in cl:
        y = coerce_year(c.get("year","") or "")
        if not is_plausible_year(y): continue
        by_src[c.get("source","other").lower()].append(y)

    # source priority
    for src in ("crossref","openalex","semanticscholar","pubmed","arxiv"):
        ys = by_src.get(src, [])
        if ys:
            # prefer the most common within that source
            y = Counter(ys).most_common(1)[0][0]
            return y, src

    # modal across all
    all_ys = [y for ys in by_src.values() for y in ys]
    if all_ys:
        y = Counter(all_ys).most_common(1)[0][0]
        return y, "consensus"

    return "", ""

def _consensus_record(ex: dict, candidates: List[Dict]) -> Tuple[Dict, List[str], Dict[str,str]]:
    if not candidates: return {}, [], {}
    clusters = _cluster_by_title(candidates)

    def cl_score(cl: List[Dict]) -> float:
        doi = _has_any_doi_agreement(cl)
        if doi: return 100.0
        return sum(_w(c.get("source")) for c in cl)

    clusters.sort(key=cl_score, reverse=True)
    top = clusters[0]

    best: Dict = {"source":"consensus"}
    provenance: Dict[str, str] = {}

    # DOI
    doi_agree = _has_any_doi_agreement(top)
    if doi_agree:
        best["doi"] = doi_agree; provenance["doi"] = "doi-agreement"
    else:
        v, _, src = _vote_field(top, "doi")
        best["doi"] = v; provenance["doi"] = src or ""

    # Title
    v, _, src = _vote_field(top, "title")
    best["title"] = v; provenance["title"] = src or ""

    # Authors
    a, _, src = _vote_authors(top)
    best["authors"] = a; provenance["authors"] = src or ""

    # Year (stronger tie-break)
    y, ysrc = _best_year(top)
    best["year"] = y; provenance["year"] = ysrc or provenance.get("doi","") or ""

    # Rest
    for k in ("journal_name","journal_abbrev","conference_name","volume","issue","pages","month","publisher","location","edition","isbn","url"):
        v, _, src = _vote_field(top, k)
        best[k] = v; provenance[k] = src or ""

    # Matching fields (vs extracted)
    matching_fields: List[str] = []
    for k in ("title","authors","year","journal_name","volume","issue","pages","doi"):
        exv = ex.get(k); bev = best.get(k)
        if k == "authors":
            exn = [_norm_author(a) for a in authors_to_list(exv or []) if _norm_author(a)]
            ben = [_norm_author(a) for a in authors_to_list(bev or []) if _norm_author(a)]
            if exn and ben and exn == ben: matching_fields.append(k)
        elif k == "title":
            if exv and bev and _title_sim(exv, bev) >= 0.82: matching_fields.append(k)
        else:
            if normalize_text(str(exv or "")) == normalize_text(str(bev or "")):
                matching_fields.append(k)

    return best, matching_fields, provenance

def select_best(state: PipelineState) -> PipelineState:
    ex = state["extracted"]
    cands = state.get("candidates", [])
    if not cands:
        state["best"] = {}
        state["matching_fields"] = []
        state["provenance"] = {}
        return state

    consensus, matching_fields, prov = _consensus_record(ex, cands)

    if not consensus.get("title") and cands:
        best = max(cands, key=lambda c: score_candidate(ex, c))
        if is_trustworthy_match(ex, best):
            consensus2, matching_fields2, prov2 = _consensus_record(ex, [best])
            # prefer single-candidate consensus only if it improves
            consensus = consensus if consensus.get("year") or consensus.get("doi") else consensus2
            matching_fields = matching_fields or matching_fields2
            prov = prov or prov2

    state["best"] = consensus or {}
    state["matching_fields"] = matching_fields or []
    state["provenance"] = prov or {}
    return state


routing.py:
from ..state import PipelineState

def should_exit(state: PipelineState) -> bool:
    cfg = state.get("_cfg")
    if state.get("_loop_detected"): return True
    if (state.get("hops") or 0) >= cfg.max_hops: return True
    if (state.get("attempts") or 0) >= cfg.max_correction_rounds: return True
    if (state.get("_stagnation") or 0) >= cfg.stagnation_patience: return True
    if not state.get("_made_changes_last_cycle") and (state.get("_stagnation",0) >= 1): return True
    ver = state.get("verification") or {}
    return bool(ver) and all(ver.values())

def route_after_verify(state: PipelineState) -> str:
    return "FormatReference" if should_exit(state) else "ApplyCorrections"


llm_correct.py:
import json
from ..state import PipelineState, ExtractedModel
from ..tools.utils import authors_to_list, normalize_month_field, normalize_text, fingerprint_state

# Fields we never allow the LLM to override once we have an authoritative value
# from online sources (best/consensus).
_LOCK_ALWAYS = {"doi", "year", "month", "title", "authors"}
# Additional fields we lock if present (helps prevent volume/issue/pages regressions)
_LOCK_IF_PRESENT = {"journal_name", "journal_abbrev", "conference_name", "volume", "issue", "pages"}

def _coerce_year(y: str) -> str:
    y = normalize_text(y)
    # Keep only a 4-digit year if present; otherwise return empty to avoid garbage like "Aug 1987"
    if len(y) >= 4:
        for i in range(len(y) - 3):
            seg = y[i:i+4]
            if seg.isdigit() and (1800 <= int(seg) <= 2100):
                return seg
    return ""

async def llm_correct(state: PipelineState) -> PipelineState:
    ref = state["reference"]
    ex = state["extracted"]
    ver = state.get("verification") or {}
    llm = state["_llm"]

    # Authoritative values from online consensus/best
    best = state.get("best") or {}

    # Build lock set: always lock _LOCK_ALWAYS if best has a value; for others, lock when present in best
    lock_fields = set()
    for k in _LOCK_ALWAYS:
        if normalize_text(best.get(k)):
            lock_fields.add(k)
    for k in _LOCK_IF_PRESENT:
        if normalize_text(best.get(k)):
            lock_fields.add(k)

    # Ask LLM for a patch, but it will be filtered below.
    prompt = (
        "You are an IEEE reference corrector. Given raw reference, current JSON, and verification booleans, "
        "return STRICT JSON correcting only fields that are missing or obviously malformed. "
        "Keys among: title, authors (list), journal_name, journal_abbrev, conference_name, volume, issue, pages, "
        "year, month, doi, publisher, location, edition, isbn, url. "
        "If you are not sure, omit the key. JSON ONLY.\n\n"
        f"Raw: {ref}\n\nCurrent: {json.dumps(ex, ensure_ascii=False)}\n\nVerification: {json.dumps(ver)}"
    )
    patch = await llm.json(prompt) or {}

    # Normalize authors + month
    if isinstance(patch.get("authors"), str):
        patch["authors"] = authors_to_list(patch["authors"])
    if patch.get("month"):
        patch["month"] = normalize_month_field(patch["month"])
    if patch.get("year"):
        patch["year"] = _coerce_year(str(patch["year"]))

    # Validate patch against pydantic model (best-effort)
    try:
        patch = ExtractedModel(**patch).dict(exclude_none=True)
    except Exception:
        patch = {}

    ex2 = dict(ex)
    changes = []

    # 1) Apply LLM patch only to fields that are NOT locked and actually improve data
    for k, v in patch.items():
        if k in lock_fields:
            # Ignore LLM for locked fields (we trust online sources over LLM guesses)
            continue
        old = ex2.get(k)
        if normalize_text(old) != normalize_text(v) and normalize_text(v):
            ex2[k] = v
            changes.append((k, old, v))

    # 2) Enforce authoritative locks from 'best' after applying LLM patch
    for k in lock_fields:
        bv = best.get(k)
        if k == "year":
            bv = _coerce_year(str(bv))
        if k == "month" and bv:
            bv = normalize_month_field(bv)
        if normalize_text(ex2.get(k)) != normalize_text(bv):
            changes.append((k, ex2.get(k), bv))
            ex2[k] = bv

    # 3) Keep basic normalizations
    if isinstance(ex2.get("authors"), str):
        # Should not happen, but guard anyway
        ex2["authors"] = authors_to_list(ex2["authors"])

    state["extracted"] = ex2
    state["corrections"] = (state.get("corrections") or []) + changes
    state["_made_changes_last_cycle"] = state.get("_made_changes_last_cycle", False) or bool(changes)

    # Update fingerprint for loop detection
    sugg = state.get("suggestions") or {}
    best_now = state.get("best") or {}
    state["_fp"] = fingerprint_state(ex2, best_now, sugg)
    return state


validate_reference.py:
import re
import json
from typing import Optional
from ..state import PipelineState

async def validate_input_reference(state: PipelineState) -> PipelineState:
    ref = state.get("reference")
    llm = state.get("_llm")

    if not ref or not isinstance(ref, str) or not llm:
        state["_skip_pipeline"] = True
        state["verification_message"] = "Reference missing or LLM not initialized."
        state["verification"] = {"is_reference": False}
        return state

    # LLM-first (and only) check
    is_reference = False
    source = "model"
    prompt = (
        "You are a bibliographic reference detector.\n"
        "Decide if the input is a complete reference (journal, conference, book, etc.).\n"
        "Respond ONLY with JSON: {\"is_reference\": true} or {\"is_reference\": false}.\n"
        f"Input:\n{ref}\nOutput:"
    )

    try:
        raw_json = await llm.json(prompt)
        if isinstance(raw_json, dict) and "is_reference" in raw_json:
            is_reference = bool(raw_json["is_reference"])
    except Exception as e:
        print(">> LLM call failed:", repr(e))
        is_reference = False

    # No heuristic fallback
    state["_skip_pipeline"] = not is_reference
    state["verification_message"] = (
        "Reference detected, proceeding with pipeline." if is_reference
        else "Reference invalid or incomplete."
    )
    state["verification"] = {"is_reference": is_reference}

    return state


parse_extract.py:
import re, json
from ..state import PipelineState, ExtractedModel
from ..tools.utils import (
    normalize_text, authors_to_list, normalize_month_field,
)
ARXIV_RE = re.compile(r'(arxiv:)?\s*(\d{4}\.\d{4,5})(v\d+)?', re.I)
DOI_RE = re.compile(r'(10\.\d{4,9}/[^\s,;]+)', re.I)

async def parse_extract(state: PipelineState) -> PipelineState:
    ref, rtype = state["reference"], state["type"]
    llm = state["_llm"]
    prompt = (
        "Parse the IEEE-style reference. Return STRICT JSON. Keys among:\n"
        "title, authors (list or string), journal_name, journal_abbrev, conference_name,\n"
        "volume, issue, pages, year, month, doi, publisher, location, edition, isbn, url.\n"
        "Omit unknown or invalid keys.\n"
        "IMPORTANT: If any extracted field contains extra characters, unexpected full stops, "
        "or other formatting issues that make it unlikely to be correct, DO NOT extract it. JSON ONLY.\n\n"
        f"Type hint: {rtype}\nReference: {ref}"
    )

    parsed = await llm.json(prompt) or {}
    if isinstance(parsed.get("authors"), str): parsed["authors"] = authors_to_list(parsed["authors"])

    if not parsed:
        m = re.search(r"“([^”]{3,})”|\"([^\"]{3,})\"", ref)
        if m:
            parsed["title"] = (m.group(1) or m.group(2)).strip()
            prefix = ref[:m.start()]
            parsed["authors"] = authors_to_list(prefix)
        if (dm := DOI_RE.search(ref)): parsed["doi"] = dm.group(1)
        if (am := ARXIV_RE.search(ref)): parsed["arxiv_id"] = am.group(2)
        if (pm := re.search(r"pp\.?\s*([\d\u2013\u2014\-]+)", ref, flags=re.I)):
            parsed["pages"] = pm.group(1).replace("\u2013","-").replace("\u2014","-")
        if (vm := re.search(r"vol\.?\s*([0-9A-Za-z]+)", ref, flags=re.I)): parsed["volume"] = vm.group(1)
        if (im := re.search(r"no\.?\s*([0-9A-Za-z]+)", ref, flags=re.I)): parsed["issue"] = im.group(1)
        if (y := re.search(r"\b(19|20)\d{2}\b", ref)): parsed["year"] = y.group(0)
    if parsed.get("month"): parsed["month"] = normalize_month_field(parsed["month"])
    try:
        parsed = ExtractedModel(**parsed).dict(exclude_none=True)
    except Exception:
        ...
    state["extracted"] = parsed
    return state


models.py:
from typing import Any, Dict, List, Optional, Tuple, Set
from typing_extensions import TypedDict

try:
    from pydantic import BaseModel
except Exception:
    class BaseModel:
        def __init__(self, **kw): ...
        def dict(self, **kw): return {}

class ExtractedModel(BaseModel):
    title: Optional[str] = None
    authors: Optional[List[str]] = None
    journal_name: Optional[str] = None
    journal_abbrev: Optional[str] = None
    conference_name: Optional[str] = None
    verified_journal_abbrev: Optional[str] = None
    volume: Optional[str] = None
    issue: Optional[str] = None
    pages: Optional[str] = None
    year: Optional[str] = None
    month: Optional[str] = None
    doi: Optional[str] = None
    publisher: Optional[str] = None
    location: Optional[str] = None
    edition: Optional[str] = None
    isbn: Optional[str] = None
    url: Optional[str] = None
    arxiv_id: Optional[str] = None

class PipelineState(TypedDict, total=False):
    reference: str
    type: str
    extracted: Dict[str, Any]
    candidates: List[Dict[str, Any]]
    best: Dict[str, Any]
    verification: Dict[str, bool]
    suggestions: Dict[str, Any]
    corrections: List[Tuple[str, Any, Any]]
    formatted: str
    report: str
    attempts: int
    hops: int
    _made_changes_last_cycle: bool
    _cfg: Any
    _llm: Any
    _http: Any
    _cache: Any
    _limiter: Any
    _sources: Any
    _llm_type_vote: Optional[str]
    csl_json: Dict[str, Any]
    bibtex: str
    _ver_score: int
    _stagnation: int
    _fp: str
    _fp_history: Set[str]
    _loop_detected: bool
    _skip_pipeline: Optional[bool]
    verification_message: Optional[str]
    matching_fields: List[str]  # NEW: List of fields that matched the best candidate

__init__.py:
from .models import PipelineState, ExtractedModel
__all__ = ["PipelineState", "ExtractedModel"]


__init__.py:
from .pipeline import build_graph, run_one
__all__ = ["build_graph","run_one"]


pipeline.py:
from langgraph.graph import StateGraph, START, END
from ..state import PipelineState
from ..config import PipelineConfig
from ..nodes import (
    init_runtime, detect_type, parse_extract, multisource_lookup, select_best,
    verify_agents, apply_corrections, llm_correct, enrich_from_best,
    format_reference, build_exports, build_report, cleanup, route_after_verify
)
from ..nodes.validate_reference import validate_input_reference
from ..nodes.verify_journal_abbrev import verify_journal_abbrev
from ..nodes.llm_format import llm_format  # NEW

def _has_llm_formatted(state: PipelineState) -> bool:
    s = (state.get("formatted") or "").strip()
    return bool(s) and (len(s) > 10)

def build_graph(cfg: PipelineConfig = PipelineConfig()) -> StateGraph:
    g = StateGraph(PipelineState)

    # Nodes
    g.add_node("InitRuntime", init_runtime)
    g.add_node("VerifyReferenceType", validate_input_reference)
    g.add_node("DetectType", detect_type)
    g.add_node("ParseExtract", parse_extract)
    g.add_node("VerifyJournalAbbrev", verify_journal_abbrev)
    g.add_node("MultiSourceLookup", multisource_lookup)
    g.add_node("SelectBest", select_best)
    g.add_node("VerifyAgents", verify_agents)
    g.add_node("ApplyCorrections", apply_corrections)
    g.add_node("LLMCorrect", llm_correct)
    g.add_node("EnrichFromBest", enrich_from_best)
    g.add_node("LLMFormat", llm_format)           # NEW: LLM-first formatter
    g.add_node("FormatReference", format_reference) # Fallback rules
    g.add_node("BuildExports", build_exports)
    g.add_node("BuildReport", build_report)
    g.add_node("Cleanup", cleanup)

    # Edges
    g.add_edge(START, "InitRuntime")
    g.add_edge("InitRuntime", "VerifyReferenceType")

    g.add_conditional_edges(
        "VerifyReferenceType",
        lambda s: "DetectType" if not s.get("_skip_pipeline") else "BuildReport",
        {"DetectType": "DetectType", "BuildReport": "BuildReport"},
    )

    g.add_edge("DetectType", "ParseExtract")
    g.add_edge("ParseExtract", "VerifyJournalAbbrev")
    g.add_edge("VerifyJournalAbbrev", "MultiSourceLookup")
    g.add_edge("MultiSourceLookup", "SelectBest")
    g.add_edge("SelectBest", "VerifyAgents")

    # After verification, either exit to formatting or continue corrections
    g.add_conditional_edges("VerifyAgents", route_after_verify, {
        "FormatReference": "LLMFormat",   # try LLM formatter first
        "ApplyCorrections": "ApplyCorrections",
    })

    g.add_edge("ApplyCorrections", "LLMCorrect")
    g.add_edge("LLMCorrect", "EnrichFromBest")
    g.add_edge("EnrichFromBest", "MultiSourceLookup")

    # If LLM formatting failed, fallback to rule-based formatter
    g.add_conditional_edges(
        "LLMFormat",
        lambda s: "BuildExports" if _has_llm_formatted(s) else "FormatReference",
        {"BuildExports":"BuildExports", "FormatReference":"FormatReference"},
    )

    g.add_edge("FormatReference", "BuildExports")
    g.add_edge("BuildExports", "BuildReport")
    g.add_edge("BuildReport", "Cleanup")
    g.add_edge("Cleanup", END)
    return g



# async def run_one(reference: str, cfg: PipelineConfig = PipelineConfig(), recursion_limit: int | None = None):
#     graph = build_graph(cfg).compile()
#     state: PipelineState = {
#         "reference": reference,
#         "_cfg": cfg,
#         "_skip_pipeline": False,            # initialize new key
#         "verification_message": ""          # initialize new key
#     }
#     return await graph.ainvoke(state, config={"recursion_limit": recursion_limit or cfg.recursion_limit})


from pathlib import Path

async def run_one(reference: str, cfg: PipelineConfig = PipelineConfig(), recursion_limit: int | None = None):
    # Build and compile the graph
    compiled = build_graph(cfg).compile()
    
    # Get PNG bytes
    png_bytes = compiled.get_graph().draw_mermaid_png()
    
    # Save to file
    graph_path = Path("pipeline_graph.png")
    graph_path.write_bytes(png_bytes)
    print(f"Graph saved to: {graph_path.resolve()}")
    
    # Prepare the initial state
    state: PipelineState = {"reference": reference, "_cfg": cfg}
    
    # Run the graph asynchronously
    return await compiled.ainvoke(state, config={"recursion_limit": recursion_limit or cfg.recursion_limit})


adapter.py:
import os
from typing import Any, Dict, Optional
from ..config import PipelineConfig
from ..logging import logger
from ..tools.utils import safe_json_load, DEFAULT_UA

try:
    import httpx
except Exception:
    httpx = None

class LLMAdapter:
    """LLM adapter supporting OpenAI, Azure OpenAI, Anthropic, Ollama.
       Provides .json(prompt) and .text(prompt) convenience methods."""
    def __init__(self, cfg: PipelineConfig):
        self.cfg = cfg
        self.provider = self._auto_provider(cfg.llm_provider)
        self._client = None
        self._init_client()

    def _auto_provider(self, p: str) -> str:
        if p != "auto": return p
        if os.getenv("OPENAI_API_KEY"): return "openai"
        if os.getenv("AZURE_OPENAI_API_KEY"): return "azure"
        if os.getenv("ANTHROPIC_API_KEY"): return "anthropic"
        if os.getenv("OLLAMA_BASE_URL") or os.getenv("OLLAMA_HOST"): return "ollama"
        return "dummy"

    def _init_client(self):
        prov = self.provider
        try:
            if prov == "openai":
                from openai import OpenAI
                base = os.getenv("OPENAI_API_BASE")
                self._client = OpenAI(base_url=base) if base else OpenAI()
            elif prov == "azure":
                from openai import AzureOpenAI
                ep = os.getenv("AZURE_OPENAI_ENDPOINT")
                ver = os.getenv("OPENAI_API_VERSION", "2024-06-01")
                if not ep: raise RuntimeError("AZURE_OPENAI_ENDPOINT is not set")
                self._client = AzureOpenAI(azure_endpoint=ep, api_version=ver)
            elif prov == "anthropic":
                import anthropic
                self._client = anthropic.AsyncAnthropic()
            elif prov == "ollama" and httpx is not None:
                base = os.getenv("OLLAMA_BASE_URL") or os.getenv("OLLAMA_HOST") or self.cfg.ollama_base
                self._client = httpx.AsyncClient(base_url=base, timeout=self.cfg.timeout_s, headers={"User-Agent": DEFAULT_UA})
        except Exception as e:
            logger.warning("LLM init failed: %s", e)
            self._client = None
            self.provider = "dummy"

    # ---------- JSON mode ----------
    async def _openai_json(self, prompt: str) -> str:
        model = self.cfg.openai_model
        resp = self._client.chat.completions.create(
            model=model,
            messages=[{"role":"system","content":"Return STRICT JSON only. No prose."},{"role":"user","content":prompt}],
            temperature=0.1, top_p=0.1, response_format={"type":"json_object"},
        )
        return resp.choices[0].message.content

    async def _azure_json(self, prompt: str) -> str:
        deployment = os.getenv("AZURE_OPENAI_DEPLOYMENT") or self.cfg.openai_model
        resp = self._client.chat.completions.create(
            model=deployment,
            messages=[{"role":"system","content":"Return STRICT JSON only. No prose."},{"role":"user","content":prompt}],
            temperature=0.1, top_p=0.1, response_format={"type":"json_object"},
        )
        return resp.choices[0].message.content

    async def _anthropic_json(self, prompt: str) -> str:
        msg = await self._client.messages.create(
            model=os.getenv("ANTHROPIC_MODEL","claude-3-5-sonnet-20240620"),
            system="Return STRICT JSON only. No prose.",
            max_tokens=1024, temperature=0.1,
            messages=[{"role":"user","content":prompt}],
        )
        texts = []
        for c in msg.content:
            if getattr(c, "type", None) == "text":
                texts.append(c.text)
        return "".join(texts)

    async def _ollama_json(self, prompt: str) -> str:
        data = {"model": self.cfg.ollama_model, "prompt": "Return STRICT JSON only.\n\n" + prompt, "stream": False}
        r = await self._client.post("/api/generate", json=data)
        r.raise_for_status()
        return r.json().get("response","")

    async def json(self, prompt: str) -> Dict[str, Any]:
        try:
            if self.provider == "openai": raw = await self._openai_json(prompt)
            elif self.provider == "azure": raw = await self._azure_json(prompt)
            elif self.provider == "anthropic": raw = await self._anthropic_json(prompt)
            elif self.provider == "ollama": raw = await self._ollama_json(prompt)
            else: return {}
            return safe_json_load(raw) or {}
        except Exception as e:
            logger.warning("LLM json() failed: %s", e)
            return {}

    # ---------- TEXT mode (for formatted references) ----------
    async def _openai_text(self, prompt: str) -> str:
        model = self.cfg.openai_model
        resp = self._client.chat.completions.create(
            model=model,
            messages=[
                {"role":"system","content":"You are a precise formatter. Output plain text only."},
                {"role":"user","content":prompt}
            ],
            temperature=0.1, top_p=0.1,
        )
        return resp.choices[0].message.content or ""

    async def _azure_text(self, prompt: str) -> str:
        deployment = os.getenv("AZURE_OPENAI_DEPLOYMENT") or self.cfg.openai_model
        resp = self._client.chat.completions.create(
            model=deployment,
            messages=[
                {"role":"system","content":"You are a precise formatter. Output plain text only."},
                {"role":"user","content":prompt}
            ],
            temperature=0.1, top_p=0.1,
        )
        return resp.choices[0].message.content or ""

    async def _anthropic_text(self, prompt: str) -> str:
        msg = await self._client.messages.create(
            model=os.getenv("ANTHROPIC_MODEL","claude-3-5-sonnet-20240620"),
            system="You are a precise formatter. Output plain text only.",
            max_tokens=1024, temperature=0.1,
            messages=[{"role":"user","content":prompt}],
        )
        texts = []
        for c in msg.content:
            if getattr(c, "type", None) == "text":
                texts.append(c.text)
        return "".join(texts)

    async def _ollama_text(self, prompt: str) -> str:
        if not self._client:
            return ""
        data = {"model": self.cfg.ollama_model, "prompt": prompt, "stream": False}
        r = await self._client.post("/api/generate", json=data)
        r.raise_for_status()
        return r.json().get("response","")

    async def text(self, prompt: str) -> str:
        try:
            if self.provider == "openai": return await self._openai_text(prompt)
            elif self.provider == "azure": return await self._azure_text(prompt)
            elif self.provider == "anthropic": return await self._anthropic_text(prompt)
            elif self.provider == "ollama": return await self._ollama_text(prompt)
            else: return ""
        except Exception as e:
            logger.warning("LLM text() failed: %s", e)
            return ""


__init__.py:
from .adapter import LLMAdapter
__all__ = ["LLMAdapter"]


SOURCES.txt:
pyproject.toml
src/refassist/__init__.py
src/refassist/config.py
src/refassist/logging.py
src/refassist.egg-info/PKG-INFO
src/refassist.egg-info/SOURCES.txt
src/refassist.egg-info/dependency_links.txt
src/refassist.egg-info/requires.txt
src/refassist.egg-info/top_level.txt
src/refassist/graphs/__init__.py
src/refassist/graphs/pipeline.py
src/refassist/llms/__init__.py
src/refassist/llms/adapter.py
src/refassist/nodes/__init__.py
src/refassist/nodes/apply_corrections.py
src/refassist/nodes/build_exports.py
src/refassist/nodes/build_report.py
src/refassist/nodes/cleanup.py
src/refassist/nodes/detect_type.py
src/refassist/nodes/enrich_from_best.py
src/refassist/nodes/format_reference.py
src/refassist/nodes/init_runtime.py
src/refassist/nodes/llm_correct.py
src/refassist/nodes/multisource_lookup.py
src/refassist/nodes/parse_extract.py
src/refassist/nodes/routing.py
src/refassist/nodes/select_best.py
src/refassist/nodes/validate_reference.py
src/refassist/nodes/verify_agents.py
src/refassist/nodes/verify_journal_abbrev.py
src/refassist/state/__init__.py
src/refassist/state/models.py
src/refassist/tools/__init__.py
src/refassist/tools/http.py
src/refassist/tools/scoring.py
src/refassist/tools/type_reconcile.py
src/refassist/tools/utils.py
src/refassist/tools/sources/__init__.py
src/refassist/tools/sources/arxiv.py
src/refassist/tools/sources/crossref.py
src/refassist/tools/sources/openalex.py
src/refassist/tools/sources/pubmed.py
src/refassist/tools/sources/semanticscholar.py
src/refassist/ui/__init__.py
src/refassist/ui/mermaid.py

requires.txt:
langgraph>=0.2.0
httpx>=0.27.0
python-dotenv>=1.0.1
cachetools>=5.3.3
rapidfuzz>=3.9.7
pydantic>=2.7.3
fastapi>=0.111.0
uvicorn>=0.30.1

[anthropic]
anthropic>=0.34.2

[openai]
openai>=1.35.10


top_level.txt:
refassist


dependency_links.txt:



styles.css:
body {
    font-family: Arial, sans-serif;
    background-color: white;
    color: #333;
}

.header-bar {
    background-color: #2e2e2e;
    padding: 20px 40px;
}

.header-bar nav a {
    color: #fff;
    text-decoration: none;
    margin-right: 15px;
    font-size: 14px;
}

.main-content {
    max-width: 1200px;
    margin: 40px auto;
    padding: 0 20px;
}

.content-box {
    display: flex;
    background:  #f4f6f9;
    padding: 30px;
    border: 1px solid  #f4f6f9;
    box-shadow: 0 2px 5px rgba(0,0,0,0.05);
}

.left-panel {
    width: 40%;
    padding-right: 30px;
    font-size: 14px;
}

.left-panel h2 {
    font-size: 16px;
    margin-bottom: 1rem;
}

.right-panel {
    width: 60%;
    display: flex;
    flex-direction: column;
}

textarea {
    width: 100%;
    padding: 10px;
    font-size: 14px;
    border: 1px solid #e0b146;
    outline: none;
    resize: vertical;
}

.upload-section {
    margin: 20px 0;
}

.upload-section a {
    color: #0073ce;
    text-decoration: none;
}

#check-btn {
    padding: 10px;
    font-size: 14px;
    background-color: #ccc;
    border: none;
    color: #fff;
    cursor: not-allowed;
}


__init__.py:


api.py:
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import asyncio
from refassist.graphs import run_one
from refassist.config import PipelineConfig

app = FastAPI(title="RefAssist API", version="0.1.0")

class ResolveRequest(BaseModel):
    reference: str

@app.post("/v1/resolve")
async def resolve(req: ResolveRequest):
    if not req.reference.strip():
        raise HTTPException(status_code=400, detail="reference is required")
    try:
        out = await run_one(req.reference, PipelineConfig())
        return {
            "type": out.get("type"),
            "formatted": out.get("formatted"),
            "report": out.get("report"),
            "verification": out.get("verification"),
            "csl_json": out.get("csl_json"),
            "bibtex": out.get("bibtex"),
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


from fastapi import FastAPI, Request, UploadFile, File, Form, HTTPException
from fastapi.responses import HTMLResponse, StreamingResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
from refassist.graphs import run_one
from refassist.config import PipelineConfig
from docx import Document
from typing import Optional, List, Tuple
import re
import asyncio
import io
import zipfile
import logging

# ---------- Setup ----------
app = FastAPI(title="RefAssist API", version="0.6.0")
app.mount("/static", StaticFiles(directory="static"), name="static")
templates = Jinja2Templates(directory="templates")

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("refassist")

def split_references(text: str) -> List[str]:
    """
    Robust reference splitter:
    - Handles IEEE [1], numbered 1., bullets -, •
    - Keeps multi-line references together
    """
    text = text.strip()
    if not text:
        return []

    # Normalize line breaks
    text = re.sub(r"\r\n?", "\n", text)
    lines = text.split("\n")

    refs = []
    current_ref = []

    # Patterns for reference start
    patterns = [
        re.compile(r"^\s*\[\d+\]"),  # [1] style
        re.compile(r"^\s*\d+\."),    # 1. style
        re.compile(r"^\s*[-•]"),     # bullet style
    ]

    for line in lines:
        line = line.strip()
        if not line:
            continue  # skip empty lines

        # Check if this line starts a new reference
        if any(p.match(line) for p in patterns):
            if current_ref:
                refs.append(" ".join(current_ref).strip())
            current_ref = [re.sub(r"^[-•\[\]\d\.]\s*", "", line)]  # remove marker
        else:
            # continuation of previous reference
            current_ref.append(line)

    if current_ref:
        refs.append(" ".join(current_ref).strip())

    return refs


# ---------- Helper: process references concurrently ----------
async def process_references(refs: List[str]) -> Tuple[List[str], Document]:
    formatted_refs: List[str] = []
    report_doc = Document()
    report_doc.add_heading("Reference Processing Report", 0)

    async def process_single(idx: int, ref: str) -> Tuple[str, dict]:
        try:
            out = await run_one(ref.strip(), PipelineConfig())
            formatted = out.get("formatted", ref)
            report_entry = {
                "idx": idx,
                "original": ref,
                "formatted": formatted,
                "report": out.get("report", "No changes")
            }
            return formatted, report_entry
        except Exception as e:
            logger.exception(f"Error processing reference {idx}")
            return ref + " [ERROR]", {
                "idx": idx,
                "original": ref,
                "formatted": None,
                "report": f"Error: {str(e)}"
            }

    tasks = [process_single(i + 1, ref) for i, ref in enumerate(refs)]
    results = await asyncio.gather(*tasks, return_exceptions=False)

    for formatted, entry in results:
        formatted_refs.append(formatted)
        report_doc.add_heading(f"Reference {entry['idx']}", level=2)
        report_doc.add_paragraph(f"Original: {entry['original']}")
        if entry['formatted']:
            report_doc.add_paragraph(f"Processed: {entry['formatted']}")
        report_doc.add_paragraph(entry['report'])

    return formatted_refs, report_doc


# ---------- OLD UI route (DISABLED) ----------
# @app.get("/", response_class=HTMLResponse)
# async def get_home(request: Request):
#     return templates.TemplateResponse("index.html", {"request": request})

# ---------- NEW UI route ----------
@app.get("/", response_class=HTMLResponse)
async def get_new_home(request: Request):
    from fastapi.responses import FileResponse
    return FileResponse("new_UI/index.html")

# Mount new UI static files
app.mount("/new_ui", StaticFiles(directory="new_UI"), name="new_ui")


# ---------- NEW API: process references for new UI ----------
@app.post("/api/process")
async def process_references_api(
    references: Optional[str] = Form(None),
    file: Optional[UploadFile] = File(None)
):
    """
    Process references and return structured data for the new UI
    """
    refs_text: Optional[str] = None

    # Case 1: pasted references
    if references and references.strip():
        refs_text = references.strip()

    # Case 2: uploaded file
    elif file:
        content = await file.read()
        try:
            if file.filename.lower().endswith(".docx"):
                from io import BytesIO
                doc = Document(BytesIO(content))
                refs_text = "\n".join(p.text for p in doc.paragraphs if p.text.strip())
            else:
                refs_text = content.decode("utf-8", errors="ignore")
        except Exception as e:
            logger.exception("Failed to read uploaded file")
            raise HTTPException(status_code=400, detail=f"Invalid file format: {str(e)}")

    if not refs_text:
        raise HTTPException(status_code=400, detail="No references provided")

    # Split and process references
    refs = split_references(refs_text)
    if not refs:
        raise HTTPException(status_code=400, detail="No references detected in input")

    # Process references and collect detailed results
    formatted_refs: List[str] = []
    detailed_reports: List[dict] = []
    
    async def process_single_detailed(idx: int, ref: str) -> Tuple[str, dict]:
        try:
            out = await run_one(ref.strip(), PipelineConfig())
            formatted = out.get("formatted", ref)
            report_entry = {
                "idx": idx,
                "original": ref,
                "formatted": formatted,
                "report": out.get("report", "No changes"),
                "status": "success"
            }
            return formatted, report_entry
        except Exception as e:
            logger.exception(f"Error processing reference {idx}")
            error_formatted = ref + " [ERROR]"
            report_entry = {
                "idx": idx,
                "original": ref,
                "formatted": error_formatted,
                "report": f"Error: {str(e)}",
                "status": "error"
            }
            return error_formatted, report_entry

    tasks = [process_single_detailed(i + 1, ref) for i, ref in enumerate(refs)]
    results = await asyncio.gather(*tasks, return_exceptions=False)

    for formatted, entry in results:
        formatted_refs.append(formatted)
        detailed_reports.append(entry)

    # Generate formatted output text
    formatted_output = "\n".join(f"[{i+1}] {ref}" for i, ref in enumerate(formatted_refs))
    
    # Generate detailed report text
    report_lines = ["Reference Processing Report", "=" * 30, ""]
    
    # Summary
    total_refs = len(detailed_reports)
    success_count = sum(1 for r in detailed_reports if r["status"] == "success")
    error_count = total_refs - success_count
    
    report_lines.append(f"Total references processed: {total_refs}")
    report_lines.append(f"Successfully processed: {success_count}")
    report_lines.append(f"Errors encountered: {error_count}")
    report_lines.append("")
    
    # Individual reference details
    for entry in detailed_reports:
        report_lines.append(f"Reference {entry['idx']}:")
        report_lines.append(f"Original: {entry['original']}")
        if entry['status'] == 'success':
            report_lines.append(f"Formatted: {entry['formatted']}")
        report_lines.append(f"Notes: {entry['report']}")
        report_lines.append("")
    
    detailed_report_text = "\n".join(report_lines)
    
    # Generate preview (first few lines of detailed report)
    preview_lines = report_lines[:15]  # First 15 lines as preview
    if len(report_lines) > 15:
        preview_lines.append("... (see full report for complete analysis)")
    preview_text = "\n".join(preview_lines)

    return {
        "success": True,
        "total_references": total_refs,
        "formatted_output": formatted_output,
        "detailed_report": detailed_report_text,
        "preview": preview_text,
        "summary": {
            "total": total_refs,
            "success": success_count,
            "errors": error_count
        }
    }


# ---------- API: download full report ----------
@app.post("/api/download-report")
async def download_full_report(
    references: Optional[str] = Form(None),
    file: Optional[UploadFile] = File(None)
):
    """
    Generate and download full report as ZIP file
    """
    # Reuse the existing logic from the original upload endpoint
    refs_text: Optional[str] = None

    if references and references.strip():
        refs_text = references.strip()
    elif file:
        content = await file.read()
        try:
            if file.filename.lower().endswith(".docx"):
                from io import BytesIO
                doc = Document(BytesIO(content))
                refs_text = "\n".join(p.text for p in doc.paragraphs if p.text.strip())
            else:
                refs_text = content.decode("utf-8", errors="ignore")
        except Exception as e:
            logger.exception("Failed to read uploaded file")
            raise HTTPException(status_code=400, detail=f"Invalid file format: {str(e)}")

    if not refs_text:
        raise HTTPException(status_code=400, detail="No references provided")

    refs = split_references(refs_text)
    if not refs:
        raise HTTPException(status_code=400, detail="No references detected in input")

    formatted_refs, report_doc = await process_references(refs)

    # Create in-memory ZIP
    zip_buffer = io.BytesIO()
    with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zipf:
        # Write TXT
        txt_content = "\n".join(f"[{i+1}] {ref}" for i, ref in enumerate(formatted_refs))
        zipf.writestr("formatted_references.txt", txt_content)

        # Write DOCX report
        docx_buffer = io.BytesIO()
        report_doc.save(docx_buffer)
        docx_buffer.seek(0)
        zipf.writestr("report.docx", docx_buffer.read())

    zip_buffer.seek(0)
    return StreamingResponse(
        zip_buffer,
        media_type="application/zip",
        headers={"Content-Disposition": 'attachment; filename="refassist_report.zip"'}
    )


# ---------- API: handle copy-paste OR file (LEGACY) ----------
@app.post("/v1/upload")
async def upload_references(
    references: Optional[str] = Form(None),
    file: Optional[UploadFile] = File(None)
):
    refs_text: Optional[str] = None

    # Case 1: pasted references
    if references and references.strip():
        refs_text = references.strip()

    # Case 2: uploaded file
    elif file:
        content = await file.read()
        try:
            if file.filename.lower().endswith(".docx"):
                from io import BytesIO
                doc = Document(BytesIO(content))
                refs_text = "\n".join(p.text for p in doc.paragraphs if p.text.strip())
            else:
                refs_text = content.decode("utf-8", errors="ignore")
        except Exception as e:
            logger.exception("Failed to read uploaded file")
            raise HTTPException(status_code=400, detail=f"Invalid file format: {str(e)}")

    if not refs_text:
        raise HTTPException(status_code=400, detail="No references provided")

    # Split and process references
    refs = split_references(refs_text)
    if not refs:
        raise HTTPException(status_code=400, detail="No references detected in input")

    formatted_refs, report_doc = await process_references(refs)

    # Create in-memory ZIP
    zip_buffer = io.BytesIO()
    with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zipf:
        # Write TXT
        txt_content = "\n".join(f"[{i+1}] {ref}" for i, ref in enumerate(formatted_refs))
        zipf.writestr("formatted_references.txt", txt_content)

        # Write DOCX report
        docx_buffer = io.BytesIO()
        report_doc.save(docx_buffer)
        docx_buffer.seek(0)
        zipf.writestr("report.docx", docx_buffer.read())

    zip_buffer.seek(0)
    return StreamingResponse(
        zip_buffer,
        media_type="application/zip",
        headers={"Content-Disposition": 'attachment; filename="results.zip"'}
    )
